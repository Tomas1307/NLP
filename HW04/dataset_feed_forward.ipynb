{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from utils_processor.processor import Processor\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_ = Processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando archivo: CrimeAndPunishment_dostoyevski.txt\n",
      "Procesando archivo: TheFallOfTheHouseOfUsher_EdgarAllanPoe.txt\n",
      "Procesando archivo: TheGambler_dostoyevski.txt\n",
      "Procesando archivo: TheIdiot_dostoyevski.txt\n",
      "Procesando archivo: TheInvisibleMan_Wells.txt\n",
      "Procesando archivo: TheMasqueOfTheRedDeath_EdgarAllanPoe.txt\n",
      "Procesando archivo: TheRaven_EdgarAllanPoe.txt\n",
      "Procesando archivo: TheSleeperAwakes_Wells.txt\n",
      "Procesando archivo: TheWarOfTheWorlds_Wells.txt\n",
      "Lista de autores en orden:\n",
      "1. fyodor dostoyevsky\n",
      "2. edgar allan poe\n",
      "3. fyodor dostoyevsky\n",
      "4. fyodor dostoyevsky\n",
      "5. h. g. wells\n",
      "6. edgar allan poe\n",
      "7. edgar allan poe\n",
      "8. h. g. wells\n",
      "9. h. g. wells\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fyodor dostoyevsky',\n",
       " 'edgar allan poe',\n",
       " 'fyodor dostoyevsky',\n",
       " 'fyodor dostoyevsky',\n",
       " 'h. g. wells',\n",
       " 'edgar allan poe',\n",
       " 'edgar allan poe',\n",
       " 'h. g. wells',\n",
       " 'h. g. wells']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Directorio donde están los archivos .txt\n",
    "data_dir = 'data/books/'\n",
    "\n",
    "# Lista para almacenar los textos y autores\n",
    "texts = []\n",
    "authors = []\n",
    "\n",
    "# Leer todos los archivos .txt del directorio\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "\n",
    "        with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            texts.append(text)  # Almacenar el texto\n",
    "            print(f\"Procesando archivo: {filename}, lineas: \", len(text))\n",
    "            \n",
    "            # Buscar el nombre del autor\n",
    "            author_match = re.search(r'Author:\\s*(.+)', text)\n",
    "            if author_match:\n",
    "                author_name = author_match.group(1).strip()\n",
    "                authors.append(author_name.lower())  # Almacenar el autor\n",
    "            else:\n",
    "                authors.append(\"Autor no encontrado\")  # En caso de no encontrarlo\n",
    "            \n",
    "            # Mostrar un fragmento del texto (opcional)\n",
    "            #print(text[:2500])\n",
    "\n",
    "# Mostrar los autores encontrados\n",
    "print(\"Lista de autores en orden:\")\n",
    "for i, author in enumerate(authors):\n",
    "    print(f\"{i+1}. {author}\")\n",
    "\n",
    "# Ahora tienes dos listas: 'texts' con los textos y 'authors' con los autores en el mismo orden\n",
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_texts(processor = Processor(), texts: list = []):\n",
    "    \"\"\"\n",
    "    Processes a list of texts and logs progress for each one, using the Processor class.\n",
    "    \n",
    "    Args:\n",
    "        processor (Processor): An instance of the Processor class.\n",
    "        texts (list): A list of text strings to process.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of processed texts.\n",
    "    \"\"\"\n",
    "    total = len(texts)\n",
    "    processed_texts = []\n",
    "    \n",
    "    for index, text in enumerate(texts):\n",
    "        processed_text = processor.preprocessing_pipeline_as_chunks(text, index, total)\n",
    "        processed_texts.append(processed_text)  # Guardamos el texto procesado como lista de tokens\n",
    "    \n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar todos los textos con el sistema de logging\n",
    "processed_texts = process_all_texts(processor_, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = []\n",
    "chunk_authors = []\n",
    "\n",
    "for i, text_list in enumerate(processed_texts):\n",
    "    author = authors[i]\n",
    "    for chunk in text_list:\n",
    "        text_chunks.append(chunk)  # Agregar cada chunk de texto\n",
    "        chunk_authors.append(author)  # Agregar el autor correspondiente\n",
    "\n",
    "# Crear un DataFrame con las listas\n",
    "df_chunks = pd.DataFrame({\n",
    "    'text_chunk': text_chunks,\n",
    "    'author': chunk_authors\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_chunk</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crime punish crime punish fyodor dostoevski tr...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acclam shi unknown youth found instant someth ...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>semyonovski squar shot write brother mihail do...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>went mad soon unti never regain saniti intens ...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>develop violent attack epilepsi suffer rest li...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>num volunt donat peopl walk life volunt financ...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5861</th>\n",
       "      <td>state mississippi grant tax exempt status inte...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>licens work freeli distribut machineread form ...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>met solicit requir know prohibit accept unsoli...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>anyon num year produc distribut project gutenb...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5865 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_chunk              author\n",
       "0     crime punish crime punish fyodor dostoevski tr...  fyodor dostoyevsky\n",
       "1     acclam shi unknown youth found instant someth ...  fyodor dostoyevsky\n",
       "2     semyonovski squar shot write brother mihail do...  fyodor dostoyevsky\n",
       "3     went mad soon unti never regain saniti intens ...  fyodor dostoyevsky\n",
       "4     develop violent attack epilepsi suffer rest li...  fyodor dostoyevsky\n",
       "...                                                 ...                 ...\n",
       "5860  num volunt donat peopl walk life volunt financ...         h. g. wells\n",
       "5861  state mississippi grant tax exempt status inte...         h. g. wells\n",
       "5862  licens work freeli distribut machineread form ...         h. g. wells\n",
       "5863  met solicit requir know prohibit accept unsoli...         h. g. wells\n",
       "5864  anyon num year produc distribut project gutenb...         h. g. wells\n",
       "\n",
       "[5865 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare the text data\n",
    "\n",
    "We already have the processed texts stored in a list called processed_texts. Each element in this list represents the chunks of text (after splitting) for a particular book.\n",
    "Each entry in processed_texts is a list where each element is a chunk of text for that book, processed based on the method we implemented for splitting into chunks of 150 words with a 25-word overlap\n",
    "\n",
    "2. Prepare the author labels\n",
    "\n",
    "We have an authors list that stores the corresponding author for each book in processed_texts. Each author appears multiple times if they have multiple books in the dataset. For example:\n",
    "python\n",
    "\n",
    "authors = ['dostoyevski', 'poe', 'dostoyevski', 'dostoyevski', 'well', 'poe', 'poe', 'well', 'well']\n",
    "\n",
    "3. Create the DataFrame structure\n",
    "\n",
    "For each processed book (i.e., processed_texts[i]), we know that all the chunks of that book correspond to a specific author. So we can assign the same author to all the chunks in that list.\n",
    "We will loop over each entry in processed_texts and for each chunk, add it to a DataFrame, along with the corresponding author.\n",
    "\n",
    "4. Steps to build the DataFrame\n",
    "\n",
    "* Initialize lists for the DataFrame: We will initialize two lists: one for text chunks and one for authors.\n",
    "* Iterate over processed_texts: For each entry in processed_texts, we extract the list of chunks and the corresponding author.\n",
    "* Add chunks and authors to the lists: For each chunk in the list of text chunks, we append it to the \"text_chunk\" list and the corresponding author to the \"author\" list.\n",
    "* Create the DataFrame: Once the lists are filled, we create a pandas DataFrame with two columns: \"text_chunk\" and \"author\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_chunks is the dataframe with the columns ['text_chunk', 'author']\n",
    "\n",
    "# Step 1: Split the dataset into 70% training and 30% test\n",
    "train_df, test_df = train_test_split(df_chunks, test_size=0.30, stratify=df_chunks['author'], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df['author'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_chunk</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>_not_ presum eh strike princ ask gania sudden ...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5225</th>\n",
       "      <td>man assur propraiet r assur propraiet r propri...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>larg soon obtain stand room among ring gambler...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4328</th>\n",
       "      <td>slightest doubt could kill get away quit easil...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>last right path pyotr petrovitch right path th...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>heart rodya num num day ago food cloth way liv...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>think pistol bound go consist whole affair sur...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>let becom attach last illus life love mean tri...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>email within num day receipt agre term full pr...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>said thought noth last night sat listen sleep ...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3694 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_chunk              author\n",
       "2328  _not_ presum eh strike princ ask gania sudden ...  fyodor dostoyevsky\n",
       "5225  man assur propraiet r assur propraiet r propri...         h. g. wells\n",
       "2100  larg soon obtain stand room among ring gambler...  fyodor dostoyevsky\n",
       "4328  slightest doubt could kill get away quit easil...         h. g. wells\n",
       "620   last right path pyotr petrovitch right path th...  fyodor dostoyevsky\n",
       "...                                                 ...                 ...\n",
       "1523  heart rodya num num day ago food cloth way liv...  fyodor dostoyevsky\n",
       "3564  think pistol bound go consist whole affair sur...  fyodor dostoyevsky\n",
       "3522  let becom attach last illus life love mean tri...  fyodor dostoyevsky\n",
       "1640  email within num day receipt agre term full pr...  fyodor dostoyevsky\n",
       "2881  said thought noth last night sat listen sleep ...  fyodor dostoyevsky\n",
       "\n",
       "[3694 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_chunk</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>evid mind hippolyt look furious restrain quit ...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>mother beg found mother live surround children...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>_now_ die listen rasp iron head lay certain li...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>although blow realli hurt found someth irresis...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049</th>\n",
       "      <td>openwork stage distanc start time peac servic ...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5621</th>\n",
       "      <td>way tri clutch bit hors could get heard scream...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>abl give littl inform princ away num month eve...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>hungri yes come along princ said mother hungri...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>sens well perhap sens realli great thing smile...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>name amalia ivanovna amalia ludwigovna amalia ...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_chunk              author\n",
       "3720  evid mind hippolyt look furious restrain quit ...  fyodor dostoyevsky\n",
       "982   mother beg found mother live surround children...  fyodor dostoyevsky\n",
       "2436  _now_ die listen rasp iron head lay certain li...  fyodor dostoyevsky\n",
       "4451  although blow realli hurt found someth irresis...         h. g. wells\n",
       "5049  openwork stage distanc start time peac servic ...         h. g. wells\n",
       "...                                                 ...                 ...\n",
       "5621  way tri clutch bit hors could get heard scream...         h. g. wells\n",
       "2778  abl give littl inform princ away num month eve...  fyodor dostoyevsky\n",
       "2397  hungri yes come along princ said mother hungri...  fyodor dostoyevsky\n",
       "2489  sens well perhap sens realli great thing smile...  fyodor dostoyevsky\n",
       "1151  name amalia ivanovna amalia ludwigovna amalia ...  fyodor dostoyevsky\n",
       "\n",
       "[411 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_chunk</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>omit caress depart condit would refus say want...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>good purpos good purpos warn warn consequ come...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>touch food num day must tell rodya dine like e...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>twist face innumer wrinkl caus eye almost disa...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>room close crowd invis eh said huxter ignor st...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>everyon frown raskolnikov sat seem pay attent ...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>light would reflect refract would get brillian...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>time would never mention gania attitud modest ...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>ah said graham forgot everyth els sat chair wi...</td>\n",
       "      <td>h. g. wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>chanc meet stranger interest us first moment w...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_chunk              author\n",
       "2166  omit caress depart condit would refus say want...  fyodor dostoyevsky\n",
       "4879  good purpos good purpos warn warn consequ come...         h. g. wells\n",
       "388   touch food num day must tell rodya dine like e...  fyodor dostoyevsky\n",
       "2087  twist face innumer wrinkl caus eye almost disa...  fyodor dostoyevsky\n",
       "4292  room close crowd invis eh said huxter ignor st...         h. g. wells\n",
       "...                                                 ...                 ...\n",
       "688   everyon frown raskolnikov sat seem pay attent ...  fyodor dostoyevsky\n",
       "4413  light would reflect refract would get brillian...         h. g. wells\n",
       "3687  time would never mention gania attitud modest ...  fyodor dostoyevsky\n",
       "4859  ah said graham forgot everyth els sat chair wi...         h. g. wells\n",
       "35    chanc meet stranger interest us first moment w...  fyodor dostoyevsky\n",
       "\n",
       "[1760 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summary_by_author(train_df, validation_df, test_df):\n",
    "    \"\"\"\n",
    "    Generates a summary table showing the number of samples per author for the training, validation, and testing sets.\n",
    "    \n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training DataFrame.\n",
    "        validation_df (pd.DataFrame): Validation DataFrame.\n",
    "        test_df (pd.DataFrame): Testing DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A summary DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_data = {\n",
    "        'Author': train_df['author'].unique(),\n",
    "        'Train': train_df['author'].value_counts(),\n",
    "        'Validation': validation_df['author'].value_counts(),\n",
    "        'Test': test_df['author'].value_counts()\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df = summary_df.fillna(0)  # Replace NaN with 0 if no samples exist for some authors\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fyodor dostoyevsky</th>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "      <td>2591</td>\n",
       "      <td>288</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h. g. wells</th>\n",
       "      <td>h. g. wells</td>\n",
       "      <td>974</td>\n",
       "      <td>108</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edgar allan poe</th>\n",
       "      <td>edgar allan poe</td>\n",
       "      <td>129</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Author  Train  Validation  Test\n",
       "author                                                         \n",
       "fyodor dostoyevsky  fyodor dostoyevsky   2591         288  1235\n",
       "h. g. wells                h. g. wells    974         108   464\n",
       "edgar allan poe        edgar allan poe    129          15    61"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_by_author(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 15888, Embedding Dimension: 1000\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Cargar el modelo Word2Vec\n",
    "word2vec_model = Word2Vec.load('data/answers/Books_1000_6.model')\n",
    "\n",
    "# Obtener la matriz de embeddings\n",
    "embedding_matrix = word2vec_model.wv.vectors  # Matriz de vectores\n",
    "\n",
    "# Tamaño del vocabulario y dimensión de los embeddings\n",
    "vocab_size = embedding_matrix.shape[0]\n",
    "embedding_dim = embedding_matrix.shape[1]\n",
    "\n",
    "print(f\"Vocab Size: {vocab_size}, Embedding Dimension: {embedding_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Crear el diccionario de palabras a índices basado en el modelo Word2Vec\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.word_index = {word: idx for idx, word in enumerate(word2vec_model.wv.index_to_key)}\n",
    "\n",
    "# Convertir los textos en secuencias de índices\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df['text_chunk'].tolist())\n",
    "val_sequences = tokenizer.texts_to_sequences(val_df['text_chunk'].tolist())\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df['text_chunk'].tolist())\n",
    "\n",
    "# Rellenar las secuencias para que todas tengan la misma longitud\n",
    "maxlen = 100  # Puedes ajustar este valor según la longitud típica de tus secuencias\n",
    "train_sequences_padded = pad_sequences(train_sequences, maxlen=maxlen, padding='post')\n",
    "val_sequences_padded = pad_sequences(val_sequences, maxlen=maxlen, padding='post')\n",
    "test_sequences_padded = pad_sequences(test_sequences, maxlen=maxlen, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Inicializar el codificador\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Codificar las etiquetas de los autores como enteros\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df['author'])\n",
    "val_labels_encoded = label_encoder.transform(val_df['author'])\n",
    "test_labels_encoded = label_encoder.transform(test_df['author'])\n",
    "\n",
    "# Convertir a formato de una-hot (one-hot encoding)\n",
    "train_labels_onehot = to_categorical(train_labels_encoded)\n",
    "val_labels_onehot = to_categorical(val_labels_encoded)\n",
    "test_labels_onehot = to_categorical(test_labels_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Flatten, Dropout\n",
    "\n",
    "def model_1(vocab_size, embedding_dim, embedding_matrix, maxlen):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \n",
    "                        weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))  # Tres clases\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def model_2(vocab_size, embedding_dim, embedding_matrix, maxlen):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \n",
    "                        weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def model_3(vocab_size, embedding_dim, embedding_matrix, maxlen):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \n",
    "                        weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Definir EarlyStopping para que detenga el entrenamiento si no hay mejora en 5 épocas\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 0.6674 - loss: 1.1671 - val_accuracy: 0.7007 - val_loss: 0.6407\n",
      "Epoch 2/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7018 - loss: 0.8272 - val_accuracy: 0.7007 - val_loss: 0.7052\n",
      "Epoch 3/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.6988 - loss: 0.8160 - val_accuracy: 0.7007 - val_loss: 0.6608\n",
      "Epoch 4/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.7075 - loss: 0.7824 - val_accuracy: 0.7007 - val_loss: 0.6396\n",
      "Epoch 5/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.6990 - loss: 0.7689 - val_accuracy: 0.7007 - val_loss: 0.6554\n",
      "Epoch 6/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.6919 - loss: 0.7518 - val_accuracy: 0.7007 - val_loss: 0.6573\n",
      "Epoch 7/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7087 - loss: 0.7311 - val_accuracy: 0.7007 - val_loss: 0.6454\n",
      "Epoch 8/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6951 - loss: 0.7304 - val_accuracy: 0.7007 - val_loss: 0.6489\n",
      "Epoch 9/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6991 - loss: 0.7256 - val_accuracy: 0.7007 - val_loss: 0.6694\n",
      "Epoch 10/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6976 - loss: 0.7193 - val_accuracy: 0.7007 - val_loss: 0.6483\n",
      "Epoch 11/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7023 - loss: 0.7028 - val_accuracy: 0.7007 - val_loss: 0.6689\n",
      "Epoch 12/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6890 - loss: 0.7099 - val_accuracy: 0.7007 - val_loss: 0.6541\n",
      "Epoch 13/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7031 - loss: 0.6998 - val_accuracy: 0.7007 - val_loss: 0.6450\n",
      "Epoch 14/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7119 - loss: 0.6791 - val_accuracy: 0.7007 - val_loss: 0.6419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c73858be90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar la primera red\n",
    "model1 = model_1(vocab_size, embedding_dim, embedding_matrix, maxlen)\n",
    "model1.fit(train_sequences_padded, train_labels_onehot, \n",
    "           validation_data=(val_sequences_padded, val_labels_onehot), epochs=1000, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 72ms/step - accuracy: 0.5914 - loss: 2.4121 - val_accuracy: 0.7007 - val_loss: 0.9292\n",
      "Epoch 2/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - accuracy: 0.6993 - loss: 0.8914 - val_accuracy: 0.7007 - val_loss: 0.7994\n",
      "Epoch 3/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.7108 - loss: 0.7819 - val_accuracy: 0.7007 - val_loss: 0.7470\n",
      "Epoch 4/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.6982 - loss: 0.7516 - val_accuracy: 0.7007 - val_loss: 0.7294\n",
      "Epoch 5/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.7092 - loss: 0.7336 - val_accuracy: 0.7007 - val_loss: 0.7245\n",
      "Epoch 6/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - accuracy: 0.7030 - loss: 0.7316 - val_accuracy: 0.7007 - val_loss: 0.7225\n",
      "Epoch 7/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.6995 - loss: 0.7301 - val_accuracy: 0.7007 - val_loss: 0.7217\n",
      "Epoch 8/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - accuracy: 0.6980 - loss: 0.7414 - val_accuracy: 0.7007 - val_loss: 0.7213\n",
      "Epoch 9/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 0.6981 - loss: 0.7318 - val_accuracy: 0.7007 - val_loss: 0.7213\n",
      "Epoch 10/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7024 - loss: 0.7368 - val_accuracy: 0.7007 - val_loss: 0.7213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c739288790>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar la segunda red\n",
    "model2 = model_2(vocab_size, embedding_dim, embedding_matrix, maxlen)\n",
    "model2.fit(train_sequences_padded, train_labels_onehot, \n",
    "           validation_data=(val_sequences_padded, val_labels_onehot), epochs=1000, callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.5892 - loss: 2.6750 - val_accuracy: 0.7007 - val_loss: 0.9042\n",
      "Epoch 2/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 123ms/step - accuracy: 0.6967 - loss: 0.8730 - val_accuracy: 0.7007 - val_loss: 0.7713\n",
      "Epoch 3/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 123ms/step - accuracy: 0.7094 - loss: 0.7631 - val_accuracy: 0.7007 - val_loss: 0.7316\n",
      "Epoch 4/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 138ms/step - accuracy: 0.7052 - loss: 0.7453 - val_accuracy: 0.7007 - val_loss: 0.7248\n",
      "Epoch 5/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 129ms/step - accuracy: 0.7082 - loss: 0.7198 - val_accuracy: 0.7007 - val_loss: 0.7224\n",
      "Epoch 6/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 133ms/step - accuracy: 0.6995 - loss: 0.7403 - val_accuracy: 0.7007 - val_loss: 0.7220\n",
      "Epoch 7/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.7098 - loss: 0.7352 - val_accuracy: 0.7007 - val_loss: 0.7222\n",
      "Epoch 8/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - accuracy: 0.7028 - loss: 0.7420 - val_accuracy: 0.7007 - val_loss: 0.7214\n",
      "Epoch 9/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 128ms/step - accuracy: 0.7058 - loss: 0.7288 - val_accuracy: 0.7007 - val_loss: 0.7217\n",
      "Epoch 10/1000\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.7007 - loss: 0.7362 - val_accuracy: 0.7007 - val_loss: 0.7215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c739b7be90>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar la tercera red\n",
    "model3 = model_3(vocab_size, embedding_dim, embedding_matrix, maxlen)\n",
    "model3.fit(train_sequences_padded, train_labels_onehot, \n",
    "           validation_data=(val_sequences_padded, val_labels_onehot), epochs=1000, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metricas frente a test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Obtener las predicciones del modelo sobre el conjunto de prueba\n",
    "predictions = model1.predict(test_sequences_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convertir las probabilidades a etiquetas (seleccionando la clase con la mayor probabilidad)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7017045454545454\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        61\n",
      "           1       0.70      1.00      0.82      1235\n",
      "           2       0.00      0.00      0.00       464\n",
      "\n",
      "    accuracy                           0.70      1760\n",
      "   macro avg       0.23      0.33      0.27      1760\n",
      "weighted avg       0.49      0.70      0.58      1760\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   0   61    0]\n",
      " [   0 1235    0]\n",
      " [   0  464    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calcular la precisión (accuracy)\n",
    "accuracy = accuracy_score(test_labels_encoded, predicted_classes)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Imprimir un informe de clasificación detallado\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, predicted_classes))\n",
    "\n",
    "# Imprimir la matriz de confusión\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_labels_encoded, predicted_classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
