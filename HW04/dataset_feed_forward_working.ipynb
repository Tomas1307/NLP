{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from utils_processor.processor import Processor\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_ = Processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando archivo: ATaleofTwoCities_Dickens.txt, lineas:  776878\n",
      "Procesando archivo: BleakHouse_Dickens.txt, lineas:  1958792\n",
      "Procesando archivo: CountofMonteCristo_Dumas.txt, lineas:  2646641\n",
      "Procesando archivo: CrimeAndPunishment_dostoyevski.txt, lineas:  1154409\n",
      "Procesando archivo: OliverTwist_Dickens.txt, lineas:  912421\n",
      "Procesando archivo: TheGambler_dostoyevski.txt, lineas:  350954\n",
      "Procesando archivo: TheIdiot_dostoyevski.txt, lineas:  1366983\n",
      "Procesando archivo: TheThreeMusketeers_Dumas.txt, lineas:  1317339\n",
      "Procesando archivo: TwentyYearsAfter_Dumas.txt, lineas:  1387344\n",
      "Lista de autores en orden:\n",
      "1. charles dickens\n",
      "2. charles dickens\n",
      "3. alexandre dumas\n",
      "4. fyodor dostoyevsky\n",
      "5. charles dickens\n",
      "6. fyodor dostoyevsky\n",
      "7. fyodor dostoyevsky\n",
      "8. alexandre dumas\n",
      "9. alexandre dumas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['charles dickens',\n",
       " 'charles dickens',\n",
       " 'alexandre dumas',\n",
       " 'fyodor dostoyevsky',\n",
       " 'charles dickens',\n",
       " 'fyodor dostoyevsky',\n",
       " 'fyodor dostoyevsky',\n",
       " 'alexandre dumas',\n",
       " 'alexandre dumas']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Directorio donde están los archivos .txt\n",
    "data_dir = 'data/books/'\n",
    "\n",
    "# Lista para almacenar los textos y autores\n",
    "texts = []\n",
    "authors = []\n",
    "\n",
    "# Leer todos los archivos .txt del directorio\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "\n",
    "        with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            texts.append(text)  # Almacenar el texto\n",
    "            print(f\"Procesando archivo: {filename}, lineas: \", len(text))\n",
    "            \n",
    "            # Buscar el nombre del autor\n",
    "            author_match = re.search(r'Author:\\s*(.+)', text)\n",
    "            if author_match:\n",
    "                author_name = author_match.group(1).strip()\n",
    "                authors.append(author_name.lower())  # Almacenar el autor\n",
    "            else:\n",
    "                authors.append(\"Autor no encontrado\")  # En caso de no encontrarlo\n",
    "            \n",
    "            # Mostrar un fragmento del texto (opcional)\n",
    "            #print(text[:2500])\n",
    "\n",
    "# Mostrar los autores encontrados\n",
    "print(\"Lista de autores en orden:\")\n",
    "for i, author in enumerate(authors):\n",
    "    print(f\"{i+1}. {author}\")\n",
    "\n",
    "# Ahora tienes dos listas: 'texts' con los textos y 'authors' con los autores en el mismo orden\n",
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_texts(processor = Processor(), texts: list = []):\n",
    "    \"\"\"\n",
    "    Processes a list of texts and logs progress for each one, using the Processor class.\n",
    "    \n",
    "    Args:\n",
    "        processor (Processor): An instance of the Processor class.\n",
    "        texts (list): A list of text strings to process.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of processed texts.\n",
    "    \"\"\"\n",
    "    total = len(texts)\n",
    "    processed_texts = []\n",
    "    \n",
    "    for index, text in enumerate(texts):\n",
    "        processed_text = processor.preprocessing_pipeline_as_chunks(text, index, total)\n",
    "        processed_texts.append(processed_text)  # Guardamos el texto procesado como lista de tokens\n",
    "    \n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar todos los textos con el sistema de logging\n",
    "processed_texts = process_all_texts(processor_, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = []\n",
    "chunk_authors = []\n",
    "\n",
    "for i, text_list in enumerate(processed_texts):\n",
    "    author = authors[i]\n",
    "    for chunk in text_list:\n",
    "        text_chunks.append(chunk)  # Agregar cada chunk de texto\n",
    "        chunk_authors.append(author)  # Agregar el autor correspondiente\n",
    "\n",
    "# Crear un DataFrame con las listas\n",
    "df_chunks = pd.DataFrame({\n",
    "    'text_chunk': text_chunks,\n",
    "    'author': chunk_authors\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_chunk</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tale num citi tale num citi stori french revol...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chapter xv knit chapter xvi still knit chapter...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>life chapter period best time worst time age w...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>king larg jaw queen plain face throne england ...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>london westminst even cocklan ghost laid round...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16890</th>\n",
       "      <td>critic reach project gutenberg goal ensur proj...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16891</th>\n",
       "      <td>num contribut project gutenberg literari archi...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16892</th>\n",
       "      <td>num num particular import maintain tax exempt ...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16893</th>\n",
       "      <td>us offer donat intern donat grate accept make ...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16894</th>\n",
       "      <td>often creat sever print edit confirm protect c...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16895 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_chunk           author\n",
       "0      tale num citi tale num citi stori french revol...  charles dickens\n",
       "1      chapter xv knit chapter xvi still knit chapter...  charles dickens\n",
       "2      life chapter period best time worst time age w...  charles dickens\n",
       "3      king larg jaw queen plain face throne england ...  charles dickens\n",
       "4      london westminst even cocklan ghost laid round...  charles dickens\n",
       "...                                                  ...              ...\n",
       "16890  critic reach project gutenberg goal ensur proj...  alexandre dumas\n",
       "16891  num contribut project gutenberg literari archi...  alexandre dumas\n",
       "16892  num num particular import maintain tax exempt ...  alexandre dumas\n",
       "16893  us offer donat intern donat grate accept make ...  alexandre dumas\n",
       "16894  often creat sever print edit confirm protect c...  alexandre dumas\n",
       "\n",
       "[16895 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare the text data\n",
    "\n",
    "We already have the processed texts stored in a list called processed_texts. Each element in this list represents the chunks of text (after splitting) for a particular book.\n",
    "Each entry in processed_texts is a list where each element is a chunk of text for that book, processed based on the method we implemented for splitting into chunks of 150 words with a 25-word overlap\n",
    "\n",
    "2. Prepare the author labels\n",
    "\n",
    "We have an authors list that stores the corresponding author for each book in processed_texts. Each author appears multiple times if they have multiple books in the dataset. For example:\n",
    "python\n",
    "\n",
    "authors = ['dostoyevski', 'poe', 'dostoyevski', 'dostoyevski', 'well', 'poe', 'poe', 'well', 'well']\n",
    "\n",
    "3. Create the DataFrame structure\n",
    "\n",
    "For each processed book (i.e., processed_texts[i]), we know that all the chunks of that book correspond to a specific author. So we can assign the same author to all the chunks in that list.\n",
    "We will loop over each entry in processed_texts and for each chunk, add it to a DataFrame, along with the corresponding author.\n",
    "\n",
    "4. Steps to build the DataFrame\n",
    "\n",
    "* Initialize lists for the DataFrame: We will initialize two lists: one for text chunks and one for authors.\n",
    "* Iterate over processed_texts: For each entry in processed_texts, we extract the list of chunks and the corresponding author.\n",
    "* Add chunks and authors to the lists: For each chunk in the list of text chunks, we append it to the \"text_chunk\" list and the corresponding author to the \"author\" list.\n",
    "* Create the DataFrame: Once the lists are filled, we create a pandas DataFrame with two columns: \"text_chunk\" and \"author\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_chunks is the dataframe with the columns ['text_chunk', 'author']\n",
    "\n",
    "# Step 1: Split the dataset into 70% training and 30% test\n",
    "train_df, test_df = train_test_split(df_chunks, test_size=0.30, stratify=df_chunks['author'], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df['author'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_chunk</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10344</th>\n",
       "      <td>elbow beg pardon said dodger look air abstract...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>pursu say emphat william guppi drop mr guppi a...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>secret use know anyth said young woman instinc...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>look keep secret condescens present visit feel...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9896</th>\n",
       "      <td>jew sooner alon counten resum former express a...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>better inform know owner hors shut cri pit cho...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8183</th>\n",
       "      <td>began count third excus would say fanci made m...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13251</th>\n",
       "      <td>take away commiss give mademoisell de chemerau...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>must curios natur island mass rock contain acr...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>harden littl wretch take away said mr bumbl im...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10643 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_chunk              author\n",
       "10344  elbow beg pardon said dodger look air abstract...     charles dickens\n",
       "2552   pursu say emphat william guppi drop mr guppi a...     charles dickens\n",
       "13609  secret use know anyth said young woman instinc...     alexandre dumas\n",
       "3369   look keep secret condescens present visit feel...     charles dickens\n",
       "9896   jew sooner alon counten resum former express a...     charles dickens\n",
       "...                                                  ...                 ...\n",
       "5799   better inform know owner hors shut cri pit cho...     alexandre dumas\n",
       "8183   began count third excus would say fanci made m...  fyodor dostoyevsky\n",
       "13251  take away commiss give mademoisell de chemerau...     alexandre dumas\n",
       "4851   must curios natur island mass rock contain acr...     alexandre dumas\n",
       "9704   harden littl wretch take away said mr bumbl im...     charles dickens\n",
       "\n",
       "[10643 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_chunk</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5881</th>\n",
       "      <td>deceiv play joke excel read ah true said mont ...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>heel head wish wos still say prewar sir let bo...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16471</th>\n",
       "      <td>would choos num atho artagnan said noth silenc...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>littl earlier morn keep account attend houseke...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13959</th>\n",
       "      <td>shall get back upon lackey hors _pardieu_ anyb...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8226</th>\n",
       "      <td>heart long anoth father polya papa fear angri ...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11409</th>\n",
       "      <td>note often grow paler take princ took note fer...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>room first floor room whitewash custom prison ...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>time littl woman ad rub head signific settl ye...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>deal amount vehem make mind speak final finish...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_chunk              author\n",
       "5881   deceiv play joke excel read ah true said mont ...     alexandre dumas\n",
       "882    heel head wish wos still say prewar sir let bo...     charles dickens\n",
       "16471  would choos num atho artagnan said noth silenc...     alexandre dumas\n",
       "3294   littl earlier morn keep account attend houseke...     charles dickens\n",
       "13959  shall get back upon lackey hors _pardieu_ anyb...     alexandre dumas\n",
       "...                                                  ...                 ...\n",
       "8226   heart long anoth father polya papa fear angri ...  fyodor dostoyevsky\n",
       "11409  note often grow paler take princ took note fer...  fyodor dostoyevsky\n",
       "7376   room first floor room whitewash custom prison ...     alexandre dumas\n",
       "1898   time littl woman ad rub head signific settl ye...     charles dickens\n",
       "2662   deal amount vehem make mind speak final finish...     charles dickens\n",
       "\n",
       "[1183 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_chunk</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12339</th>\n",
       "      <td>quit sure reach culmin point happi num day saw...</td>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4185</th>\n",
       "      <td>spain itali mercédè father could join fear liv...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15378</th>\n",
       "      <td>found pale fatigu inquir whether ill fact said...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9926</th>\n",
       "      <td>empti comfort said mrs corney much inde said b...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6920</th>\n",
       "      <td>crush singl touch word breath yes self thought...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>poor dear girl found much admir good disposit ...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14473</th>\n",
       "      <td>dispos convers reclin corner carriag num pass ...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14223</th>\n",
       "      <td>smile indic knew stori well wish relat recomme...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16470</th>\n",
       "      <td>shall begin portho arami drew back disappoint ...</td>\n",
       "      <td>alexandre dumas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>slowli shook shadow turn shall go home father ...</td>\n",
       "      <td>charles dickens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5069 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_chunk              author\n",
       "12339  quit sure reach culmin point happi num day saw...  fyodor dostoyevsky\n",
       "4185   spain itali mercédè father could join fear liv...     alexandre dumas\n",
       "15378  found pale fatigu inquir whether ill fact said...     alexandre dumas\n",
       "9926   empti comfort said mrs corney much inde said b...     charles dickens\n",
       "6920   crush singl touch word breath yes self thought...     alexandre dumas\n",
       "...                                                  ...                 ...\n",
       "2448   poor dear girl found much admir good disposit ...     charles dickens\n",
       "14473  dispos convers reclin corner carriag num pass ...     alexandre dumas\n",
       "14223  smile indic knew stori well wish relat recomme...     alexandre dumas\n",
       "16470  shall begin portho arami drew back disappoint ...     alexandre dumas\n",
       "223    slowli shook shadow turn shall go home father ...     charles dickens\n",
       "\n",
       "[5069 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summary_by_author(train_df, validation_df, test_df):\n",
    "    \"\"\"\n",
    "    Generates a summary table showing the number of samples per author for the training, validation, and testing sets.\n",
    "    \n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training DataFrame.\n",
    "        validation_df (pd.DataFrame): Validation DataFrame.\n",
    "        test_df (pd.DataFrame): Testing DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A summary DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_data = {\n",
    "        'Author': train_df['author'].unique(),\n",
    "        'Train': train_df['author'].value_counts(),\n",
    "        'Validation': validation_df['author'].value_counts(),\n",
    "        'Test': test_df['author'].value_counts()\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df = summary_df.fillna(0)  # Replace NaN with 0 if no samples exist for some authors\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alexandre dumas</th>\n",
       "      <td>charles dickens</td>\n",
       "      <td>4744</td>\n",
       "      <td>527</td>\n",
       "      <td>2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charles dickens</th>\n",
       "      <td>alexandre dumas</td>\n",
       "      <td>3307</td>\n",
       "      <td>368</td>\n",
       "      <td>1575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fyodor dostoyevsky</th>\n",
       "      <td>fyodor dostoyevsky</td>\n",
       "      <td>2592</td>\n",
       "      <td>288</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Author  Train  Validation  Test\n",
       "author                                                         \n",
       "alexandre dumas        charles dickens   4744         527  2260\n",
       "charles dickens        alexandre dumas   3307         368  1575\n",
       "fyodor dostoyevsky  fyodor dostoyevsky   2592         288  1234"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_by_author(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 300\n",
    "word2vec_model = Word2Vec.load(f'data/answers/Books_{embedding_size}_6.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, processor_):\n",
    "    X = []\n",
    "    print(\"Procesando textos...\")\n",
    "    \n",
    "    for text in df['text_chunk']:\n",
    "        processed_tokens = processor_.preprocessing_pipeline(text)\n",
    "        X.append(processed_tokens)\n",
    "    \n",
    "    # Convertir tokens a índices\n",
    "    vocab = word2vec_model.wv.key_to_index\n",
    "    X_indices = []\n",
    "    for tokens in X:\n",
    "        indices = []\n",
    "        for token in tokens:\n",
    "            indices.append(vocab.get(token, 0))  # 0 para tokens desconocidos\n",
    "        X_indices.append(indices)\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando textos...\n",
      "Procesando textos...\n",
      "Procesando textos...\n"
     ]
    }
   ],
   "source": [
    "X_train = prepare_data(train_df, processor_)\n",
    "X_val = prepare_data(val_df, processor_)\n",
    "X_test = prepare_data(test_df, processor_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud máxima de secuencia: 121\n"
     ]
    }
   ],
   "source": [
    "max_length = max(\n",
    "    max(len(x) for x in X_train),\n",
    "    max(len(x) for x in X_val),\n",
    "    max(len(x) for x in X_test)\n",
    ")\n",
    "print(f\"Longitud máxima de secuencia: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
    "X_val_padded = pad_sequences(X_val, maxlen=max_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = label_encoder.transform(train_df['author'])\n",
    "y_val = label_encoder.transform(val_df['author'])\n",
    "y_test = label_encoder.transform(test_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = to_categorical(y_train)\n",
    "y_val_onehot = to_categorical(y_val)\n",
    "y_test_onehot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Crear el modelo\n",
    "def create_model(vocab_size, embedding_dim, embedding_matrix):\n",
    "    model = models.Sequential([\n",
    "        # Capa de Embedding\n",
    "        layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            weights=[embedding_matrix],\n",
    "            trainable=False\n",
    "        ),\n",
    "        \n",
    "        # Capas de procesamiento bidireccional\n",
    "        layers.Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
    "        layers.GlobalMaxPooling1D(),\n",
    "        \n",
    "        # Capas densas\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Capa de salida\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2vec_model.wv.key_to_index) + 1  # +1 para el token de padding\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_size))\n",
    "for word, i in word2vec_model.wv.key_to_index.items():\n",
    "    embedding_matrix[i] = word2vec_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.91890199e-02,  5.21713018e-01, -1.65519714e-02, ...,\n",
       "        -3.39471728e-01, -2.32708510e-02,  2.90578604e-01],\n",
       "       [ 4.55714166e-02,  5.29075682e-01, -4.92591932e-02, ...,\n",
       "        -3.48181039e-01,  1.85044250e-03,  2.48613954e-01],\n",
       "       [ 5.07456213e-02,  5.03904164e-01, -4.64888029e-02, ...,\n",
       "        -3.29032212e-01,  8.04999610e-04,  2.47850284e-01],\n",
       "       ...,\n",
       "       [ 3.24375462e-03,  1.43650617e-03,  8.10264726e-04, ...,\n",
       "         1.30300445e-03,  2.12241639e-03, -1.63700184e-04],\n",
       "       [-1.00655516e-03, -2.20268336e-03,  1.28425634e-03, ...,\n",
       "         2.25621625e-03, -4.39817901e-04, -2.68187234e-03],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pesos de las clases:\n",
      "Clase 0: 0.7478218100056211\n",
      "Clase 1: 1.0727749218828748\n",
      "Clase 2: 1.368698559670782\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPesos de las clases:\")\n",
    "for class_idx, weight in class_weight_dict.items():\n",
    "    print(f\"Clase {class_idx}: {weight}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(vocab_size, embedding_size, embedding_matrix)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando el modelo...\n",
      "Epoch 1/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 86ms/step - accuracy: 0.3274 - loss: 1.4371 - val_accuracy: 0.3111 - val_loss: 1.1197\n",
      "Epoch 2/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - accuracy: 0.3285 - loss: 1.1699 - val_accuracy: 0.2434 - val_loss: 1.1163\n",
      "Epoch 3/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - accuracy: 0.3520 - loss: 1.1113 - val_accuracy: 0.2434 - val_loss: 1.2703\n",
      "Epoch 4/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 89ms/step - accuracy: 0.4225 - loss: 1.0476 - val_accuracy: 0.2325 - val_loss: 1.1012\n",
      "Epoch 5/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - accuracy: 0.4223 - loss: 1.0379 - val_accuracy: 0.4455 - val_loss: 1.1708\n",
      "Epoch 6/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - accuracy: 0.4487 - loss: 1.0170 - val_accuracy: 0.3111 - val_loss: 1.6583\n",
      "Epoch 7/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.4504 - loss: 1.0043 - val_accuracy: 0.5799 - val_loss: 1.0265\n",
      "Epoch 8/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - accuracy: 0.4905 - loss: 0.9804 - val_accuracy: 0.2316 - val_loss: 1.1458\n",
      "Epoch 9/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - accuracy: 0.5110 - loss: 0.9715 - val_accuracy: 0.4125 - val_loss: 0.9786\n",
      "Epoch 10/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - accuracy: 0.4422 - loss: 1.0073 - val_accuracy: 0.2434 - val_loss: 1.1584\n",
      "Epoch 11/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.4667 - loss: 1.0002 - val_accuracy: 0.4455 - val_loss: 1.1482\n",
      "Epoch 12/20\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 83ms/step - accuracy: 0.4633 - loss: 0.9965 - val_accuracy: 0.2316 - val_loss: 1.1436\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEntrenando el modelo...\")\n",
    "history = model.fit(\n",
    "    X_train_padded, \n",
    "    y_train,\n",
    "    validation_data=(X_val_padded, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando en el conjunto de prueba...\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.4331 - loss: 0.9867\n",
      "\n",
      "Precisión en el conjunto de prueba: 0.4172\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluando en el conjunto de prueba...\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f\"\\nPrecisión en el conjunto de prueba: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step\n",
      "\n",
      "Reporte de clasificación:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "   alexandre dumas       0.56      0.12      0.20      2260\n",
      "   charles dickens       0.91      0.48      0.63      1575\n",
      "fyodor dostoyevsky       0.29      0.88      0.44      1234\n",
      "\n",
      "          accuracy                           0.42      5069\n",
      "         macro avg       0.59      0.49      0.42      5069\n",
      "      weighted avg       0.60      0.42      0.39      5069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hacer predicciones\n",
    "y_pred = model.predict(X_test_padded)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Mostrar reporte de clasificación\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred_classes, \n",
    "                          target_names=label_encoder.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
