{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.binary_search.inverted_index import InvertedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = InvertedIndex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decidimos hacer el inverted index con un parametro de ocurrences para saber si es necesario o no (Esto se hizo pensando en acceder de forma mas rapida a los recursos del indice invertido dependienod de si es RRDV o Binary search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 12:18:11,385 - InvertedIndex - INFO - Starting complete inverted index pipeline\n",
      "2024-09-04 12:18:11,385 - InvertedIndex - INFO - Step 1: Processing texts\n",
      "2024-09-04 12:18:11,387 - TextProcessor - INFO - Starting text processing pipeline\n",
      "2024-09-04 12:18:11,387 - TextProcessor - INFO - Reading files from directory: data/docs-raw-texts/\n",
      "2024-09-04 12:18:11,454 - TextProcessor - INFO - Finished reading files. Time taken: 0.07 seconds\n",
      "2024-09-04 12:18:11,455 - TextProcessor - INFO - Replacing titles in text and cleaning newlines\n",
      "C:\\Users\\Rog\\Desktop\\Andes\\10\\Natural Language Processing\\NLP\\HW01\\algorithms\\binary_search\\text_processor.py:82: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataFrame[\"text\"][i] = dataFrame[\"text\"][i].replace(dataFrame[\"title\"][i] + \".\", \"\")\n",
      "C:\\Users\\Rog\\Desktop\\Andes\\10\\Natural Language Processing\\NLP\\HW01\\algorithms\\binary_search\\text_processor.py:83: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataFrame[\"text\"][i] = dataFrame[\"text\"][i].replace(\"\\n\", \"\")\n",
      "2024-09-04 12:18:11,477 - TextProcessor - INFO - Finished replacing titles. Time taken: 0.02 seconds\n",
      "2024-09-04 12:18:11,477 - TextProcessor - INFO - Processing and normalizing text\n",
      "2024-09-04 12:18:13,133 - TextProcessor - INFO - Completed text processing pipeline. Total time taken: 1.75 seconds\n",
      "2024-09-04 12:18:13,133 - InvertedIndex - INFO - Step 2: Applying vectorizer and processing\n",
      "2024-09-04 12:18:13,133 - InvertedIndex - INFO - Applying vectorizer and processing\n",
      "2024-09-04 12:18:13,237 - InvertedIndex - INFO - Finished vectorization and processing. Time taken: 0.10 seconds\n",
      "2024-09-04 12:18:13,237 - InvertedIndex - INFO - Step 3: Creating inverted index\n",
      "2024-09-04 12:18:13,237 - InvertedIndex - INFO - Creating inverted index\n",
      "2024-09-04 12:18:29,290 - InvertedIndex - INFO - Finished creating inverted index. Time taken: 16.05 seconds\n",
      "2024-09-04 12:18:29,291 - InvertedIndex - INFO - Step 4: Saving inverted index\n",
      "2024-09-04 12:18:29,291 - InvertedIndex - INFO - Saving inverted index to inverted_index_without_ocurrences.json\n",
      "2024-09-04 12:18:29,359 - InvertedIndex - INFO - Inverted index successfully saved to inverted_index_without_ocurrences.json\n",
      "2024-09-04 12:18:29,361 - InvertedIndex - INFO - Completed inverted index pipeline. Total time taken: 17.98 seconds\n"
     ]
    }
   ],
   "source": [
    "index = inverted_index.inverted_index_complete_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora traemos los datos de los queries y de los documentos ya procesada, esto se hace desde sus respectivas clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 12:18:29,377 - INFO - QueryProcessor initialized\n",
      "2024-09-04 12:18:29,377 - TextProcessor - INFO - Starting text processing pipeline\n",
      "2024-09-04 12:18:29,377 - TextProcessor - INFO - Starting text processing pipeline\n",
      "2024-09-04 12:18:29,377 - INFO - Starting text processing pipeline\n",
      "2024-09-04 12:18:29,378 - TextProcessor - INFO - Reading files from directory: data/docs-raw-texts/\n",
      "2024-09-04 12:18:29,378 - TextProcessor - INFO - Reading files from directory: data/docs-raw-texts/\n",
      "2024-09-04 12:18:29,378 - INFO - Reading files from directory: data/docs-raw-texts/\n",
      "2024-09-04 12:18:29,439 - TextProcessor - INFO - Finished reading files. Time taken: 0.06 seconds\n",
      "2024-09-04 12:18:29,439 - TextProcessor - INFO - Finished reading files. Time taken: 0.06 seconds\n",
      "2024-09-04 12:18:29,439 - INFO - Finished reading files. Time taken: 0.06 seconds\n",
      "2024-09-04 12:18:29,440 - TextProcessor - INFO - Replacing titles in text and cleaning newlines\n",
      "2024-09-04 12:18:29,440 - TextProcessor - INFO - Replacing titles in text and cleaning newlines\n",
      "2024-09-04 12:18:29,440 - INFO - Replacing titles in text and cleaning newlines\n",
      "C:\\Users\\Rog\\Desktop\\Andes\\10\\Natural Language Processing\\NLP\\HW01\\algorithms\\binary_search\\text_processor.py:82: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataFrame[\"text\"][i] = dataFrame[\"text\"][i].replace(dataFrame[\"title\"][i] + \".\", \"\")\n",
      "C:\\Users\\Rog\\Desktop\\Andes\\10\\Natural Language Processing\\NLP\\HW01\\algorithms\\binary_search\\text_processor.py:83: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataFrame[\"text\"][i] = dataFrame[\"text\"][i].replace(\"\\n\", \"\")\n",
      "2024-09-04 12:18:29,460 - TextProcessor - INFO - Finished replacing titles. Time taken: 0.02 seconds\n",
      "2024-09-04 12:18:29,460 - TextProcessor - INFO - Finished replacing titles. Time taken: 0.02 seconds\n",
      "2024-09-04 12:18:29,460 - INFO - Finished replacing titles. Time taken: 0.02 seconds\n",
      "2024-09-04 12:18:29,462 - TextProcessor - INFO - Processing and normalizing text\n",
      "2024-09-04 12:18:29,462 - TextProcessor - INFO - Processing and normalizing text\n",
      "2024-09-04 12:18:29,462 - INFO - Processing and normalizing text\n",
      "2024-09-04 12:18:31,243 - TextProcessor - INFO - Completed text processing pipeline. Total time taken: 1.86 seconds\n",
      "2024-09-04 12:18:31,243 - TextProcessor - INFO - Completed text processing pipeline. Total time taken: 1.86 seconds\n",
      "2024-09-04 12:18:31,243 - INFO - Completed text processing pipeline. Total time taken: 1.86 seconds\n",
      "2024-09-04 12:18:31,251 - INFO - Read 35 queries\n",
      "2024-09-04 12:18:31,259 - INFO - Processed all queries\n"
     ]
    }
   ],
   "source": [
    "from algorithms.binary_search.query_processor import QueryProcessor\n",
    "from algorithms.binary_search.text_processor import TextProcessor\n",
    "\n",
    "texts = TextProcessor()\n",
    "queries = QueryProcessor()\n",
    "\n",
    "text_df = texts.process_texts()\n",
    "queries_df = queries.process_queries()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el procesamiento se esta haciendo los pasos de:\n",
    "* tokenizacion\n",
    "* lowercase\n",
    "* remover stop_words\n",
    "* Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "viendose los resultados como"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>text</th>\n",
       "      <th>text_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>william beaumont physiolog digest imag sourc n...</td>\n",
       "      <td>[william, beaumont, physiolog, digest, imag, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002</td>\n",
       "      <td>cover wonder adventur nil novemb 20 1858 swedi...</td>\n",
       "      <td>[cover, wonder, adventur, nil, novemb, 20, 185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003</td>\n",
       "      <td>ferdinand mari vicomt de lessep 18051894 novem...</td>\n",
       "      <td>[ferdinand, mari, vicomt, de, lessep, 18051894...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004</td>\n",
       "      <td>mickey mous star walk fame imag flickr user fr...</td>\n",
       "      <td>[mickey, mous, star, walk, fame, imag, flickr,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005</td>\n",
       "      <td>eugen paul wigner 19021995 novemb 17 1902 hung...</td>\n",
       "      <td>[eugen, paul, wigner, 19021995, novemb, 17, 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  identifier                                               text  \\\n",
       "0        001  william beaumont physiolog digest imag sourc n...   \n",
       "1        002  cover wonder adventur nil novemb 20 1858 swedi...   \n",
       "2        003  ferdinand mari vicomt de lessep 18051894 novem...   \n",
       "3        004  mickey mous star walk fame imag flickr user fr...   \n",
       "4        005  eugen paul wigner 19021995 novemb 17 1902 hung...   \n",
       "\n",
       "                                           text_list  \n",
       "0  [william, beaumont, physiolog, digest, imag, s...  \n",
       "1  [cover, wonder, adventur, nil, novemb, 20, 185...  \n",
       "2  [ferdinand, mari, vicomt, de, lessep, 18051894...  \n",
       "3  [mickey, mous, star, walk, fame, imag, flickr,...  \n",
       "4  [eugen, paul, wigner, 19021995, novemb, 17, 19...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>query</th>\n",
       "      <th>processed_query</th>\n",
       "      <th>query_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q01</td>\n",
       "      <td>Fabrication of music instruments</td>\n",
       "      <td>[fabric, music, instrument]</td>\n",
       "      <td>[fabric, music, instrument]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q02</td>\n",
       "      <td>famous German poetry</td>\n",
       "      <td>[famous, german, poetri]</td>\n",
       "      <td>[famous, german, poetri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q03</td>\n",
       "      <td>Romanticism</td>\n",
       "      <td>[romantic]</td>\n",
       "      <td>[romantic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q04</td>\n",
       "      <td>University of Edinburgh research</td>\n",
       "      <td>[univers, edinburgh, research]</td>\n",
       "      <td>[univers, edinburgh, research]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q06</td>\n",
       "      <td>bridge construction</td>\n",
       "      <td>[bridg, construct]</td>\n",
       "      <td>[bridg, construct]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  identifier                             query  \\\n",
       "0        q01  Fabrication of music instruments   \n",
       "1        q02              famous German poetry   \n",
       "2        q03                       Romanticism   \n",
       "3        q04  University of Edinburgh research   \n",
       "4        q06               bridge construction   \n",
       "\n",
       "                  processed_query                      query_list  \n",
       "0     [fabric, music, instrument]     [fabric, music, instrument]  \n",
       "1        [famous, german, poetri]        [famous, german, poetri]  \n",
       "2                      [romantic]                      [romantic]  \n",
       "3  [univers, edinburgh, research]  [univers, edinburgh, research]  \n",
       "4              [bridg, construct]              [bridg, construct]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultas BOOLEANAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el AND hicimos uso de los metodos de intersect dentro de binary_search.py donde hayamos, como dice su nombre, la interseccion  entre 2 listas como si fuera una busqueda de AND. Esto se realiza para todas las queries con documento iterando sobre sus terminos en el indice invertido. Este metodo lo podemos ver en funcionamiento desde la clase de search_engine.py donde finalmente hacemos el llamado para procesar los queries y arrojar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 12:18:31,282 - INFO - QueryProcessor initialized\n",
      "2024-09-04 12:18:31,299 - INFO - SearchEngine initialized\n",
      "2024-09-04 12:18:31,302 - INFO - Results file generated: results/BSII-AND-queries_result.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q01\n",
      "q02 d291,d293\n",
      "q03 d105,d147,d152,d283,d291,d318\n",
      "q04 d286\n",
      "q05 d026,d029,d069,d257,d297,d303,d329\n",
      "q06 d004,d034\n",
      "q07 d108,d110,d117,d205,d251\n",
      "q08 d198,d205,d223\n",
      "q09 d231\n",
      "q10 d250,d277\n",
      "q11\n",
      "q12\n",
      "q13 d132,d150,d176,d184,d229,d250,d277\n",
      "q14 d121,d271\n",
      "q15 d192,d194,d203,d210\n",
      "q16 d179\n",
      "q17\n",
      "q18\n",
      "q19 d129,d221,d240,d282\n",
      "q20 d020,d032,d167,d211\n",
      "q21\n",
      "q22\n",
      "q23 d136,d174\n",
      "q24 d037,d046,d294\n",
      "q25 d025,d031,d090,d139,d254\n",
      "q26\n",
      "q27 d257,d265\n",
      "q28 d169\n",
      "q29\n",
      "q30\n",
      "q31 d150,d174\n",
      "q32\n",
      "q33 d029,d185\n",
      "q34 d105\n",
      "q35 d094,d133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from algorithms.binary_search.search_engine import SearchEngine\n",
    "\n",
    "\n",
    "query_processor = QueryProcessor()\n",
    "\n",
    "search_engine = SearchEngine()\n",
    "output_file = \"results/BSII-AND-queries_result.txt\"\n",
    "search_engine.generate_results_file(queries_df, output_file)\n",
    "\n",
    "with open(output_file, 'r') as f:\n",
    "    print(f.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
