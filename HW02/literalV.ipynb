{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción de Modelos N-Gram con Suavizado Laplace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importar Librerías Necesarias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cargar los Datasets\n",
    "\n",
    "Aquí cargamos los archivos de entrenamiento de los datasets 20N y BAC. Los archivos están en formato CSV y contienen las oraciones preprocesadas en una columna llamada `unique`. Después de cargar los datos, verificamos el contenido con un `print` de las primeras filas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset 20N:\n",
      "   Unnamed: 0                                             unique\n",
      "0        3599  <s> on fri NUM apr NUM NUM NUM NUM gmt markfri...\n",
      "1       12086  <s> can somebody please help me with informati...\n",
      "2        4281  <s> hi there could some kind soul tell me what...\n",
      "3       12513  <s> d9bertil dtek chalmers se bertil jonell wr...\n",
      "4        7177  <s> in article 1993apr20 NUM NUM chpc org rbou...\n",
      "\n",
      "Primeras filas del dataset BAC:\n",
      "   Unnamed: 0                                             unique\n",
      "0      260662  <s> sorry i havnt writen in so long i ve been ...\n",
      "1      163528  <s> this is how i was feeling earlier today oh...\n",
      "2      140457  <s> sometime ago i read this in a book the har...\n",
      "3      288965  <s> to aj for listening to me tonight we cover...\n",
      "4      330387  <s> there is something else i would like to bi...\n"
     ]
    }
   ],
   "source": [
    "datos20N = pd.read_csv('20N_01_training.csv')\n",
    "datosBAC = pd.read_csv('BAC_01_training.csv')\n",
    "\n",
    "print(\"Primeras filas del dataset 20N:\")\n",
    "print(datos20N.head())\n",
    "print(\"\\nPrimeras filas del dataset BAC:\")\n",
    "print(datosBAC.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Separación de Oraciones\n",
    "\n",
    "Cada oración en los datasets ya está  preprocesada y almacenada en la columna `unique`. En esta sección, extraemos las oraciones y las almacenamos como listas de tokens para facilitar la construcción de los N-gramas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplos de oraciones tokenizadas del dataset 20N:\n",
      "[['<s>', 'on', 'fri', 'NUM', 'apr', 'NUM', 'NUM', 'NUM', 'NUM', 'gmt', 'markfried', 'fellensiek', 'ins413j', 'mdw056', 'cc', 'monash', 'edu', 'au', 'wrote', 'if', 'you', 're', 'considering', 'buying', 'a', 'system', 'with', 'a', 'view', 'to', 'using', 'it', 'to', 'run', 'unix', 'linux', 'bsd', 'etc', 'or', 'some', 'other', 'special', 'software', 'there', 'is', 'a', 'good', 'chance', 'that', 'it', 'will', 'not', 'work', 'with', 'the', 'diamond', 'cards', 'this', 'is', 'due', 'to', 'diamond', 's', 'propriety', 'attitude', 'to', 'it', 's', 'hardware', 'it', 's', 'impossible', 'to', 'get', 'free', 'information', 'from', 'them', 'about', 'their', 'chips', 'specifically', 'their', 'dot', 'clocks', 'without', 'paying', 'and', 'signing', 'non', 'disclosure', 'agreements', 'this', 'made', 'it', 'impossible', 'for', 'the', 'free', 'software', 'foundation', 'to', 'provide', 'x', 'windows', 'compatibility', 'with', 'these', 'cards', 'as', 'diamond', 'didn', 't', 'want', 'to', 'divulge', 'programming', 'neccessities', 'considering', 'the', 'above', 'and', 'some', 'postings', 'about', 'diamond', 's', 'bad', 'attitute', 'towars', 'customers', 'i', 'ordered', 'and', 'actixge', 'vlb', '2m', 'card', 'it', 'will', 'arive', 'these', 'days', 'penio', 'penev', 'x7423', 'NUM', 'NUM', 'NUM', 'w', 'internet', 'penev', 'venezia', 'rockefeller', 'edu', 'disclaimer', 'all', 'oppinions', 'are', 'mine', '</s>'], ['<s>', 'can', 'somebody', 'please', 'help', 'me', 'with', 'information', 'about', 'an', 'american', 'magnetics', 'corporation', 'magstripe', 'card', 'reader', 'that', 'i', 'recently', 'bought', 'locally', 'from', 'a', 'surplus', 'dealer', 'on', 'the', 'rear', 'it', 'has', 'the', 'following', 'information', 'american', 'magnetics', 'corporation', 'carson', 'ca', 'usa', 'magstripe', 'card', 'reader', 'model', 'NUM', 'p', 'n', 'NUM', 'NUM', 'it', 'is', 'fitted', 'with', 'a', 'cable', 'with', 'a', 'rs232', 'cannon', 'NUM', 'pin', 'connector', 'on', 'the', 'end', 'and', 'has', 'a', 'separate', 'power', 'connector', 'like', 'the', 'once', 'used', 'with', 'wall', '<UNK>', 'frode', 'frode', 'weierud', 'phone', 'NUM', 'NUM', 'NUM', 'cern', 'sl', 'fax', 'NUM', 'NUM', 'NUM', 'ch', 'NUM', 'geneva', 'NUM', 'e', 'mail', 'frode', 'dxcern', 'cern', 'ch', 'switzerland', 'or', 'weierud', 'cernvm', 'cern', 'ch', '</s>']]\n",
      "\n",
      "Ejemplos de oraciones tokenizadas del dataset BAC:\n",
      "[['<s>', 'sorry', 'i', 'havnt', 'writen', 'in', 'so', 'long', 'i', 've', 'been', 'hella', 'busy', 'partying', 'and', 'such', 'i', 've', 'still', 'been', 'having', '<UNK>', 'simular', 'dreams', 'but', 'as', 'of', 'late', 'a', 'new', 'person', 'has', 'entered', 'them', 'i', 'first', 'saw', 'him', 'NUM', 'nights', 'ago', 'after', 'caden', 'had', 'healed', 'enough', 'to', 'be', 'up', 'and', 'moving', 'again', 'we', 'desided', 'we', 'd', 'travle', 'during', 'the', 'night', 'to', 'be', 'less', 'noticable', 'as', 'we', 'were', 'travling', 'threw', 'a', 'wood', 'we', 'came', 'across', 'his', 'body', 'we', 'thought', 'he', 'was', 'dead', 'but', 'as', 'we', 'moved', 'past', 'him', 'a', 'groan', 'from', 'the', 'body', 'made', 'us', 'turn', 'back', 'we', 'werent', 'sure', 'if', 'he', 'was', 'dead', 'or', 'a', 'gray', 'we', 'had', 'to', 'move', 'around', 'him', '<UNK>', 'you', 'cant', 'be', 'sure', 'if', 'a', 'person', 'is', 'a', 'gray', 'unless', 'you', 'can', 'see', 'there', 'skin', 'grays', 'still', 'have', 'intelegence', 'and', 'emotion', 'but', 'mostly', 'the', 'emotions', 'they', 'feel', 'are', 'hatred', 'and', 'loathing', 'for', 'other', 'human', 'beings', 'so', 'it', 'being', 'to', 'dark', 'to', 'see', 'him', 'clearly', 'we', 'didnt', 'exactly', 'rush', 'forward', 'to', 'help', 'him', 'justin', 'lit', 'up', 'a', 'lantern', 'and', 'moved', 'closer', 'to', 'the', 'body', 'very', 'slowly', 'the', 'person', 'was', 'lying', 'on', 'his', 'stomache', 'so', 'we', 'could', 'not', 'tell', 'if', 'he', 'had', 'many', 'injuries', 'as', 'justin', 'moved', 'closer', 'we', 'could', 'see', 'that', 'the', 'person', 'was', 'not', 'a', 'gray', 'when', 'he', 'was', 'about', 'NUM', 'feet', 'away', 'from', 'the', 'body', 'the', 'person', 'lept', 'to', 'his', 'feet', 'and', 'fell', 'into', 'a', 'fighting', 'stance', 'his', 'dark', 'eyes', 'were', 'filled', 'with', 'rage', 'and', 'pain', 'his', 'close', 'were', 'in', 'tatters', 'and', 'his', 'shirt', 'was', 'barely', 'there', 'threw', 'the', 'torn', 'material', 'i', 'could', 'see', 'NUM', 'deep', 'slash', 'marks', 'across', 'his', 'chest', 'and', 'NUM', 'across', 'his', 'upper', 'thight', 'he', 'was', 'still', 'bleeding', 'badly', 'justin', 'tried', 'to', 'talk', 'to', 'him', 'and', 'calm', 'him', 'down', 'that', 'didnt', 'work', 'to', 'well', 'the', 'man', 'had', 'pulled', 'a', 'dagger', 'out', 'of', 'his', 'belt', 'and', 'threw', 'it', 'at', 'justin', 'luckily', 'it', 'missed', 'him', 'unluckily', 'it', 'hit', 'my', 'horse', 'it', 'wasnt', 'a', 'mortal', 'blow', 'but', 'it', 'was', 'enough', 'to', 'cause', 'a', 'lot', 'of', 'pain', 'i', 'got', 'extremly', 'angery', 'and', 'started', 'yelling', 'at', 'the', 'new', 'person', 'he', 'responded', 'by', 'calming', 'down', 'and', 'passing', 'out', 'red', 'moved', 'in', 'and', 'tied', 'his', 'arm', 'behind', 'his', 'back', 'then', 'threw', 'him', 'on', 'the', 'back', 'of', 'the', 'horse', 'we', 'travled', 'about', 'an', 'hour', 'more', 'until', 'we', 'found', 'a', 'clearing', 'after', 'we', 'set', 'up', 'camp', 'i', 'went', 'to', 'work', 'on', 'fixing', 'up', 'the', 'new', 'comers', 'wounds', 'unlucky', 'for', 'me', 'he', 'came', 'to', 'during', 'the', 'middle', 'of', 'the', '<UNK>', 'and', 'tried', 'to', 'fight', 'his', 'way', 'up', 'he', 'reopened', 'all', 'of', 'the', 'wounds', 'i', 'had', 'stitched', 'closed', 'i', 'had', 'to', 'have', 'red', 'and', 'justin', 'hold', 'him', 'down', 'for', 'about', 'NUM', 'hours', 'so', 'i', 'could', 'stitch', 'up', 'all', 'of', 'his', 'numorous', 'wounds', 'by', 'the', 'time', 'i', 'had', 'finished', 'he', 'had', 'calmed', 'down', 'and', 'stayed', 'put', 'when', 'red', 'and', 'justin', 'released', 'him', 'we', 'had', 'some', 'NUM', 'stand', 'gaurd', 'over', 'him', 'the', 'whole', 'night', 'just', 'incase', 'any', 'thing', 'happened', 'over', 'the', 'next', 'few', 'days', 'he', 'became', 'a', 'little', 'more', 'friendly', 'i', 've', 'desided', 'his', 'name', 'id', 'matthew', 'he', 'doesnt', 'talk', 'to', 'much', 'so', 'far', 'in', 'NUM', 'days', 'i', 've', 'only', 'heard', 'him', 'say', 'thank', 'you', 'and', 'here', 'he', 's', 'become', 'quite', 'helpful', 'i', 'just', 'wish', 'i', 'knew', 'more', 'about', 'him', '</s>'], ['<s>', 'this', 'is', 'how', 'i', 'was', 'feeling', 'earlier', 'today', 'oh', 'my', 'god', 'i', 'had', 'the', 'best', 'day', 'with', 'emma', 'we', 'decided', 'that', 'we', 'd', 'go', 'into', 'town', 'for', 'coffee', 'yeah', 'like', 'that', 'would', 'actually', 'happen', 'and', 'it', 'was', 'just', 'great', 'we', 'were', 'in', 'burger', 'king', 'for', 'aaaaaages', 'just', 'catchin', 'up', 'n', 'stuff', 'which', 'was', 'great', 'fun', 'then', 'we', 'went', 'wanders', 'for', 'ages', 'prince', 's', 'square', 'went', 'to', 'the', 'basement', 'and', 'then', 'got', 'lost', 'and', 'on', 'the', 'way', 'up', 'buchannan', 'street', 'for', 'like', 'the', 'eighth', 'time', 'we', 'were', 'stopped', 'by', 'the', 'fucking', 'weirdo', 'gouranga', 'guy', 'with', 'the', 'weird', 'yellow', 'rash', 'felt', 'kinda', 'bad', 'though', 'cause', 'we', 'were', 'both', 'doin', 'so', 'well', 'and', 'then', 'as', 'soon', 'as', 'he', 'announced', 'that', 'there', 'was', 'chanting', 'monks', 'on', 'the', 'cd', 'i', 'pure', 'burst', 'out', 'laughin', 'in', 'his', 'face', 'with', 'emma', 'following', 'en', 'suit', 'aw', 'wee', 'shame', 'for', 'da', 'man', 'so', 'then', 'back', 'in', 'e', 'k', 'traversed', 'to', 'emma', 's', 'for', 'a', 'tad', 'to', 'see', 'her', 'folks', 'and', 'bro', 'cause', 'i', 'aint', 'spoken', 'to', 'them', 'in', 'ages', 'so', 'yeah', 'twas', 'great', '<UNK>', 'introduction', '<UNK>', 'peepoz', 'xx', 'lol', 'ok', 'that', 'was', 'a', 'bad', 'attempt', 'hey', 'there', 'so', 'what', 's', 'been', 'goin', 'on', 'what', 'is', 'going', 'on', 'and', 'what', 'will', 'go', 'on', 'today', 'on', 'homo', 'well', 'what', 'a', 'busy', 'cunt', 'i', 've', 'been', 'thursday', 'we', 'went', 'on', 'a', 'trip', 'to', 'the', 'edinburgh', 'barracks', 'for', 'the', 'big', 'army', 'trip', 'open', 'day', 'extravaganza', 'twas', 'alright', 'we', 'broke', 'down', 'on', 'the', 'way', 'there', 'got', 'there', 'it', 'pissed', 'it', 'down', 'we', 'ate', 'talked', 'to', 'hot', 'army', 'men', 'who', 'think', 'they', 're', 'funny', 'and', 'actually', 'they', 'were', 'rather', 'watched', 'the', 'mad', 'demonstration', 'thing', 'with', 'bikes', 'and', 'tanks', 'all', 'good', 'but', 'the', 'NUM', 'of', 'us', 'had', 'to', 'share', 'the', 'bus', 'with', 'like', 'NUM', 'guys', 'from', '<UNK>', 'academy', 'i', 'swear', 'to', 'god', 'they', 'were', 'the', 'most', 'fucking', 'rude', 'and', 'horribly', 'racist', 'guys', 'i', 've', 'ever', 'met', 'they', 'were', 'making', 'a', 'hell', 'of', 'a', 'lot', 'of', 'fun', 'of', 'the', 'rejects', 'which', 'granted', 'we', 'do', 'everyday', 'but', 'never', 'to', 'their', 'faces', 'and', 'we', 'also', 'never', 'go', 'as', 'far', 'as', 'to', 'call', 'wee', 'tony', 'a', 'retarded', 'kid', 'from', '2nd', 'year', 'gremlin', 'and', 'then', 'they', 'turned', 'on', 'this', 'girl', 'in', '3rd', 'year', 'now', 'at', 'first', 'we', 'hadnt', 'heard', 'them', 'but', 'we', 'started', 'picking', 'up', 'on', 'what', 'they', 'were', 'saying', 'to', 'her', 'stuff', 'like', 'dirty', 'black', 'bitch', 'boo', 'and', 'occasionally', 'saying', 'stuff', 'like', 'where', 's', 'my', 'white', 'hood', 'i', 'felt', 'like', 'fuckin', '<UNK>', 'them', 'but', 'of', 'course', 'i', 'wouldn', 't', 'cause', 'i', 'd', 'get', 'the', 'crap', 'beaten', 'out', 'of', 'me', 'but', 'it', 'was', 'all', 'good', 'cause', 'as', 'they', 'started', 'to', 'leave', 'we', 'all', 'chucked', 'bottles', 'and', 'done', 'a', 'massive', 'cheer', 'felt', 'great', 'so', 'then', 'thurday', 'night', 'was', 'the', 'school', 'show', 'cleverly', 'titled', 'this', 'isnae', 'broadway', 'i', 'have', 'got', 'ta', 'say', 'it', 'was', 'reeeeeally', 'good', 'a', 'talent', 'show', 'but', 'with', 'a', 'script', 'and', 'with', 'a', 'hint', 'of', 'a', 'glaswegian', 'twist', 'some', 'of', 'it', '<UNK>', 'class', 'there', 'was', 'this', 'little', 'girl', 'from', '2nd', 'year', 'i', 'think', 'singing', 'and', 'her', 'voice', 'was', 'just', 'amazing', 'throw', 'in', 'some', 'proper', 'glesga', 'banter', 'dancing', 'singing', 'acting', 'and', 'an', 'arse', 'dressed', 'up', 'in', 'old', 'mens', 'clothes', 'and', 'you', 've', 'got', 'a', 'show', 'i', 'of', 'course', 'was', 'looking', 'fabulous', 'lol', 'but', 'the', 'weirdest', 'thing', 'madeleine', 's', 'boyfriend', 'adam', 'whom', 'i', 've', 'never', 'formally', 'met', 'kept', 'staring', 'at', 'me', 'at', 'first', 'i', 'thought', 'i', 'was', 'just', 'being', 'paranoid', 'but', 'jennifer', 'and', 'joe', 'said', 'they', 'had', 'noticed', 'it', 'too', 'it', 'wasn', 't', 'like', 'a', 'glare', 'or', 'anything', 'just', 'looking', 'how', 'rather', 'odd', 'anyways', 'moving', 'on', 'tonight', 'is', 'the', 'big', 'eviction', 'in', 'big', 'bro', 'i', 'swear', 'to', 'god', 'if', 'dan', 'leaves', 'ill', 'cry', 'he', 's', 'great', 'and', 'vanessa', 's', 'just', 'a', 'bint', 'plus', 'poor', 'emma', 'locked', 'in', 'the', 'bedsit', 'again', 'she', 'didn', 't', 'even', 'do', 'anything', 'for', 'fuck', 'sake', 'bastards', 'well', 'i', 'm', 'gon', 'na', 'sign', 'off', 'now', 'i', 'think', 'andi', 's', 'out', 'with', 'david', 'and', 'so', 'won', 't', 'be', 'on', 'and', 'angus', 'has', 'like', 'disappeared', 'off', 'the', 'face', 'of', 'the', 'fucking', 'planet', 'i', 'say', 'that', 'and', 'he', 'll', 'probably', 'come', 'on', 'in', 'like', 'the', 'next', 'NUM', 'minutes', 'trust', 'me', 'love', 'me', 'xxx', 'p', 's', 'i', 'really', 'got', 'ta', 'get', 'more', 'peeps', 'readin', 'this', 'cause', 'i', 'never', 'have', 'enough', 'comments', 'cheers', 'to', 'those', 'who', 'do', 'as', 'in', 'joe', 'and', 'andi', 'lol', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "def separarOraciones(datos):\n",
    "    \"\"\"\n",
    "    Tokeniza las oraciones de un DataFrame a partir de la columna 'unique'\n",
    "\n",
    "    Parámetros:\n",
    "    datos (pd.DataFrame): DataFrame que contiene una columna 'unique' con las oraciones\n",
    "\n",
    "    Retorna:\n",
    "    list: Lista de oraciones tokenizadas, donde cada oración es una lista de tokens\n",
    "    \"\"\"\n",
    "    oracionesSeparadas = []\n",
    "    for oracion in datos['unique']:\n",
    "        tokens = oracion.split() \n",
    "        oracionesSeparadas.append(tokens)\n",
    "    return oracionesSeparadas\n",
    "\n",
    "oracionesSeparadas20N = separarOraciones(datos20N)\n",
    "oracionesSeparadasBAC = separarOraciones(datosBAC)\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(\"Ejemplos de oraciones tokenizadas del dataset 20N:\")\n",
    "print(oracionesSeparadas20N[:2])\n",
    "print(\"\\nEjemplos de oraciones tokenizadas del dataset BAC:\")\n",
    "print(oracionesSeparadasBAC[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Construcción del Modelo de Unigramas\n",
    "\n",
    "En esta sección, construimos el modelo de unigramas para ambos datasets. Un unigrama es simplemente una palabra en sí misma. Contamos la frecuencia de cada palabra y calculamos su probabilidad aplicando el suavizado de Laplace, que asegura que todas las palabras, incluso aquellas que no aparecieron en el conjunto de entrenamiento, tengan una probabilidad mayor a 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario 20N: 71294\n",
      "Tamaño del vocabulario BAC: 328708\n"
     ]
    }
   ],
   "source": [
    "def construirModeloUnigrama(oracionesSeparadas):\n",
    "    \"\"\"\n",
    "    Construye el modelo de unigramas a partir de las oraciones tokenizadas\n",
    "\n",
    "    Parámetros:\n",
    "    oracionesSeparadas (list): Lista de oraciones tokenizadas\n",
    "\n",
    "    Retorna:\n",
    "    tuple: Un Counter con las frecuencias de los unigramas y el total de palabras\n",
    "    \"\"\"\n",
    "    cuentaUnigrama = Counter()\n",
    "    totalPalabras = 0\n",
    "    for oracion in oracionesSeparadas:\n",
    "        for palabra in oracion:\n",
    "            cuentaUnigrama[palabra] += 1\n",
    "            totalPalabras += 1\n",
    "    return cuentaUnigrama, totalPalabras\n",
    "\n",
    "unigrama20N, totalPalabras20N = construirModeloUnigrama(oracionesSeparadas20N)\n",
    "unigramaBAC, totalPalabrasBAC = construirModeloUnigrama(oracionesSeparadasBAC)\n",
    "\n",
    "# Tamaños de vocabulario\n",
    "tamanoVocabulario20N = len(unigrama20N)\n",
    "tamanoVocabularioBAC = len(unigramaBAC)\n",
    "\n",
    "print(f\"Tamaño del vocabulario 20N: {tamanoVocabulario20N}\")\n",
    "print(f\"Tamaño del vocabulario BAC: {tamanoVocabularioBAC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de 'NUM' en 20N: 0.049626061618955615\n",
      "Probabilidad de 'NUM' en BAC: 0.016980981559552168\n"
     ]
    }
   ],
   "source": [
    "def probabilidadUnigrama(cuentaUnigrama, totalPalabras, palabra, tamanoVocabulario):\n",
    "    \"\"\"\n",
    "    Calcula la probabilidad de un unigrama\n",
    "\n",
    "    Parámetros:\n",
    "    cuentaUnigrama (Counter): Contador de frecuencias de unigramas\n",
    "    totalPalabras (int): Total de palabras en el corpus\n",
    "    palabra (str): Palabra para la cual se calcula la probabilidad\n",
    "    tamanoVocabulario (int): Tamaño del vocabulario\n",
    "\n",
    "    Retorna:\n",
    "    float: Probabilidad suavizada del unigrama\n",
    "    \"\"\"\n",
    "    return (cuentaUnigrama.get(palabra, 0) + 1) / (totalPalabras + tamanoVocabulario)\n",
    "\n",
    "palabra = \"NUM\"\n",
    "print(f\"Probabilidad de '{palabra}' en 20N: {probabilidadUnigrama(unigrama20N, totalPalabras20N, palabra, tamanoVocabulario20N)}\")\n",
    "print(f\"Probabilidad de '{palabra}' en BAC: {probabilidadUnigrama(unigramaBAC, totalPalabrasBAC, palabra, tamanoVocabularioBAC)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Construcción del Modelo de Bigramas\n",
    "\n",
    "Ahora creamos el modelo de bigramas, que calcula las probabilidades de aparición de una palabra dada la palabra anterior en la secuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de bigramas en 20N: 4380316\n",
      "Total de bigramas en BAC: 111110021\n"
     ]
    }
   ],
   "source": [
    "def construirModeloBigrama(oracionesSeparadas):\n",
    "    \"\"\"\n",
    "    Construye el modelo de bigramas a partir de las oraciones tokenizadas\n",
    "\n",
    "    Parámetros:\n",
    "    oracionesSeparadas (list): Lista de oraciones tokenizadas\n",
    "\n",
    "    Retorna:\n",
    "    tuple: Un defaultdict de Counters con las frecuencias de bigramas y el total de bigramas\n",
    "    \"\"\"\n",
    "    cuentaBigramas = defaultdict(Counter)\n",
    "    totalBigramas = 0\n",
    "    for oracion in oracionesSeparadas:\n",
    "        for i in range(len(oracion) - 1):\n",
    "            palabra1 = oracion[i]\n",
    "            palabra2 = oracion[i+1]\n",
    "            cuentaBigramas[palabra1][palabra2] += 1\n",
    "            totalBigramas += 1\n",
    "    return cuentaBigramas, totalBigramas\n",
    "\n",
    "bigrama20N, totalBigramas20N = construirModeloBigrama(oracionesSeparadas20N)\n",
    "bigramaBAC, totalBigramasBAC = construirModeloBigrama(oracionesSeparadasBAC)\n",
    "\n",
    "print(f\"Total de bigramas en 20N: {totalBigramas20N}\")\n",
    "print(f\"Total de bigramas en BAC: {totalBigramasBAC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de 'NUM NUM' en 20N: 0.2827226024474749\n",
      "Probabilidad de 'NUM NUM' en BAC: 0.1300816697730177\n"
     ]
    }
   ],
   "source": [
    "def probabilidadBigrama(cuentaBigramas, cuentaUnigrama, palabra1, palabra2, tamanoVocabulario):\n",
    "    \"\"\"\n",
    "    Calcula la probabilidad de un bigrama\n",
    "\n",
    "    Parámetros:\n",
    "    cuentaBigramas (defaultdict(Counter)): Frecuencias de bigramas\n",
    "    cuentaUnigrama (Counter): Frecuencias de unigramas\n",
    "    palabra1 (str): Primera palabra del bigrama\n",
    "    palabra2 (str): Segunda palabra del bigrama\n",
    "    tamanoVocabulario (int): Tamaño del vocabulario\n",
    "\n",
    "    Retorna:\n",
    "    float: Probabilidad suavizada del bigrama\n",
    "    \"\"\"\n",
    "    frecuenciaBigram = cuentaBigramas.get(palabra1, {}).get(palabra2, 0)\n",
    "    frecuenciaUnigram = cuentaUnigrama.get(palabra1, 0)\n",
    "    return (frecuenciaBigram + 1) / (frecuenciaUnigram + tamanoVocabulario)\n",
    "\n",
    "palabra1 = \"NUM\"\n",
    "palabra2 = \"NUM\"\n",
    "print(f\"Probabilidad de '{palabra1} {palabra2}' en 20N: {probabilidadBigrama(bigrama20N, unigrama20N, palabra1, palabra2, tamanoVocabulario20N)}\")\n",
    "print(f\"Probabilidad de '{palabra1} {palabra2}' en BAC: {probabilidadBigrama(bigramaBAC, unigramaBAC, palabra1, palabra2, tamanoVocabularioBAC)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Construcción del Modelo de Trigramas\n",
    "\n",
    "Por último, construimos el modelo de trigramas, que calcula las probabilidades de que una palabra aparezca en función de las dos palabras anteriores. Al igual que con los otros modelos, utilizamos suavizado de Laplace para evitar que la probabilidad sea cero si un trigramq no está\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de trigramas en 20N: 4365281\n",
      "Total de trigramas en BAC: 110844901\n"
     ]
    }
   ],
   "source": [
    "def crearDefaultdictCounter():\n",
    "    \"\"\"\n",
    "    Crea un defaultdict de Counter, para utilizar en el modelo de trigramas\n",
    "\n",
    "    Retorna:\n",
    "    defaultdict(Counter): Un defaultdict que retorna un Counter por defecto\n",
    "    \"\"\"\n",
    "    return defaultdict(Counter)\n",
    "\n",
    "def construirModeloTrigrama(oracionesSeparadas):\n",
    "    \"\"\"\n",
    "    Construye el modelo de trigramas a partir de las oraciones tokenizadas\n",
    "\n",
    "    Parámetros:\n",
    "    oracionesSeparadas (list): Lista de oraciones tokenizadas\n",
    "\n",
    "    Retorna:\n",
    "    tuple: Un defaultdict anidado con las frecuencias de trigramas y el total de trigramas\n",
    "    \"\"\"\n",
    "    cuentaTrigramas = defaultdict(crearDefaultdictCounter)  \n",
    "    totalTrigramas = 0\n",
    "    for oracion in oracionesSeparadas:\n",
    "        for i in range(len(oracion) - 2):\n",
    "            palabra1 = oracion[i]\n",
    "            palabra2 = oracion[i+1]\n",
    "            palabra3 = oracion[i+2]\n",
    "            cuentaTrigramas[palabra1][palabra2][palabra3] += 1\n",
    "            totalTrigramas += 1\n",
    "    return cuentaTrigramas, totalTrigramas\n",
    "\n",
    "trigrama20N, totalTrigramas20N = construirModeloTrigrama(oracionesSeparadas20N)\n",
    "trigramaBAC, totalTrigramasBAC = construirModeloTrigrama(oracionesSeparadasBAC)\n",
    "\n",
    "print(f\"Total de trigramas en 20N: {totalTrigramas20N}\")\n",
    "print(f\"Total de trigramas en BAC: {totalTrigramasBAC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de 'NUM NUM NUM' en 20N: 0.2762623444373791\n",
      "Probabilidad de 'NUM NUM NUM' en BAC: 0.12507562155254687\n"
     ]
    }
   ],
   "source": [
    "def probabilidadTrigrama(cuentaTrigramas, cuentaBigramas, palabra1, palabra2, palabra3, tamanoVocabulario):\n",
    "    \"\"\"\n",
    "    Calcula la probabilidad de un trigrama\n",
    "\n",
    "    Parámetros:\n",
    "    cuentaTrigramas (defaultdict): Frecuencias de trigramas\n",
    "    cuentaBigramas (defaultdict(Counter)): Frecuencias de bigramas\n",
    "    palabra1 (str): Primera palabra del trigrama\n",
    "    palabra2 (str): Segunda palabra del trigrama\n",
    "    palabra3 (str): Tercera palabra del trigrama\n",
    "    tamanoVocabulario (int): Tamaño del vocabulario\n",
    "\n",
    "    Retorna:\n",
    "    float: Probabilidad suavizada del trigrama\n",
    "    \"\"\"\n",
    "    frecuenciaTrigram = cuentaTrigramas.get(palabra1, {}).get(palabra2, {}).get(palabra3, 0)\n",
    "    frecuenciaBigram = cuentaBigramas.get(palabra1, {}).get(palabra2, 0)\n",
    "    return (frecuenciaTrigram + 1) / (frecuenciaBigram + tamanoVocabulario)\n",
    "\n",
    "palabra1 = \"NUM\"\n",
    "palabra2 = \"NUM\"\n",
    "palabra3 = \"NUM\"\n",
    "print(f\"Probabilidad de '{palabra1} {palabra2} {palabra3}' en 20N: {probabilidadTrigrama(trigrama20N, bigrama20N, palabra1, palabra2, palabra3, tamanoVocabulario20N)}\")\n",
    "print(f\"Probabilidad de '{palabra1} {palabra2} {palabra3}' en BAC: {probabilidadTrigrama(trigramaBAC, bigramaBAC, palabra1, palabra2, palabra3, tamanoVocabularioBAC)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Guardar los Modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos guardados exitosamente.\n"
     ]
    }
   ],
   "source": [
    "def guardarModelo(modelo, nombreArchivo):\n",
    "    \"\"\"\n",
    "    Guarda un modelo utilizando pickle\n",
    "\n",
    "    Parámetros:\n",
    "    modelo: Modelo a guardar\n",
    "    nombreArchivo (str): Nombre del archivo donde se guardará el modelo.\n",
    "    \"\"\"\n",
    "    with open(nombreArchivo, 'wb') as archivo:\n",
    "        pickle.dump(modelo, archivo)\n",
    "\n",
    "# Guardar los modelos de 20N\n",
    "guardarModelo(unigrama20N, '20N_01_unigramas.pkl')\n",
    "guardarModelo(bigrama20N, '20N_01_bigramas.pkl')\n",
    "guardarModelo(trigrama20N, '20N_01_trigramas.pkl')\n",
    "\n",
    "# Guardar los modelos de BAC\n",
    "guardarModelo(unigramaBAC, 'BAC_01_unigramas.pkl')\n",
    "guardarModelo(bigramaBAC, 'BAC_01_bigramas.pkl')\n",
    "guardarModelo(trigramaBAC, 'BAC_01_trigramas.pkl')\n",
    "\n",
    "print(\"Modelos guardados exitosamente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
