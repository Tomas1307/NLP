{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "from text_to_num import text2num\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESO DE TOKENIZADO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESO DE TOKENIZADO PARA DATOS 20N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de datos del paso anterior\n",
    "df_20n = pd.read_csv(\"20N_unified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecciónn de columna correspondiente a las oraciones\n",
    "body_20n = df_20n[['body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones básicas de tokenizado\n",
    "\n",
    "La función normalize_text se encarga de convertir a todas las letras de las oraciones en minúsculas, y posteriormente elimina todos los caracteres especiales como las comas y los puntos y separa cada signo de puntuación con un espacio\n",
    "\n",
    "La función words_to_numbers maneja un caso excepcional para convertir palabras que representen números como dígitos, para ello utiliza la librería text2num para convertir las palabras que sean necesarias a lo largo del corpus\n",
    "\n",
    "La función replace_digits se encarga de convertir todos los digitos del corpus en el caracter NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    return text\n",
    "\n",
    "def words_to_numbers(token):\n",
    "    try:\n",
    "        return str(text2num(token,'en'))\n",
    "    except ValueError:\n",
    "        return token\n",
    "\n",
    "def replace_digits(token):\n",
    "    if token.isdigit():\n",
    "        return 'NUM'\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se aplica la normalización antes de realizar el tokenizado de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/3604201721.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_20n['normalized'] = body_20n['body'].apply(normalize_text)\n"
     ]
    }
   ],
   "source": [
    "body_20n['normalized'] = body_20n['body'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, se hace una tokenización con la librería word_tokenize de nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/814313017.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_20n['tokenized'] = body_20n['normalized'].apply(word_tokenize)\n"
     ]
    }
   ],
   "source": [
    "body_20n['tokenized'] = body_20n['normalized'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se realiza el reemplazo de palabras que representen dígitos en dígitos, esto con el objetivo de facilitar la conversión de dígitos en caracteres NUM en el siguiente paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/282450380.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_20n['digits'] = body_20n['tokenized'].apply(lambda tokens: [words_to_numbers(token) for token in tokens])\n"
     ]
    }
   ],
   "source": [
    "body_20n['digits'] = body_20n['tokenized'].apply(lambda tokens: [words_to_numbers(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de haber hecho el reemplazo de palabras, se hace el reemplazo de todos los dígitos en un caracter denominado NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_20n['replacement'] = body_20n['digits'].apply(lambda tokens: [replace_digits(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se añade un <s> al comienzo de cada oración y se añade un </S> al término de cada oración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_20n['sentence'] = body_20n['replacement'].apply(lambda tokens: ['<s>'] + tokens + ['</s>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se realiza un conteo de todos los tokens en el corpus, si un token sólo aparece una vez, entonces se reemplaza por el caracter <UNK>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = [token for tokens in body_20n['sentence'] for token in tokens]\n",
    "token_freq = Counter(all_tokens)\n",
    "\n",
    "def replace_unique_tokens(tokens, freq_dict):\n",
    "    return [token if freq_dict[token] > 1 else '<UNK>' for token in tokens]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazo del token en el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_20n['unique'] = body_20n['sentence'].apply(lambda tokens: replace_unique_tokens(tokens, token_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportación de resultados obtenidos para realizar la división de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_20n = pd.DataFrame(body_20n['unique'].apply(lambda tokens: ' '.join(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_20n.to_csv(\"20n_tokenized.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>normalized</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>digits</th>\n",
       "      <th>replacement</th>\n",
       "      <th>sentence</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Archive-name: atheism/resources Alt-atheism-ar...</td>\n",
       "      <td>archive name  atheism resources alt atheism ar...</td>\n",
       "      <td>[archive, name, atheism, resources, alt, athei...</td>\n",
       "      <td>[archive, name, atheism, resources, alt, athei...</td>\n",
       "      <td>[archive, name, atheism, resources, alt, athei...</td>\n",
       "      <td>[&lt;s&gt;, archive, name, atheism, resources, alt, ...</td>\n",
       "      <td>[&lt;s&gt;, archive, name, atheism, resources, alt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Archive-name: atheism/introduction Alt-atheism...</td>\n",
       "      <td>archive name  atheism introduction alt atheism...</td>\n",
       "      <td>[archive, name, atheism, introduction, alt, at...</td>\n",
       "      <td>[archive, name, atheism, introduction, alt, at...</td>\n",
       "      <td>[archive, name, atheism, introduction, alt, at...</td>\n",
       "      <td>[&lt;s&gt;, archive, name, atheism, introduction, al...</td>\n",
       "      <td>[&lt;s&gt;, archive, name, atheism, introduction, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In article &lt;65974@mimsy.umd.edu&gt; mangoe@cs.umd...</td>\n",
       "      <td>in article  65974 mimsy umd edu  mangoe cs umd...</td>\n",
       "      <td>[in, article, 65974, mimsy, umd, edu, mangoe, ...</td>\n",
       "      <td>[in, article, 65974, mimsy, umd, edu, mangoe, ...</td>\n",
       "      <td>[in, article, NUM, mimsy, umd, edu, mangoe, cs...</td>\n",
       "      <td>[&lt;s&gt;, in, article, NUM, mimsy, umd, edu, mango...</td>\n",
       "      <td>[&lt;s&gt;, in, article, NUM, mimsy, umd, edu, mango...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dmn@kepler.unh.edu (...until kings become phil...</td>\n",
       "      <td>dmn kepler unh edu     until kings become phil...</td>\n",
       "      <td>[dmn, kepler, unh, edu, until, kings, become, ...</td>\n",
       "      <td>[dmn, kepler, unh, edu, until, kings, become, ...</td>\n",
       "      <td>[dmn, kepler, unh, edu, until, kings, become, ...</td>\n",
       "      <td>[&lt;s&gt;, dmn, kepler, unh, edu, until, kings, bec...</td>\n",
       "      <td>[&lt;s&gt;, dmn, kepler, unh, edu, until, kings, bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In article &lt;N4HY.93Apr5120934@harder.ccr-p.ida...</td>\n",
       "      <td>in article  n4hy 93apr5120934 harder ccr p ida...</td>\n",
       "      <td>[in, article, n4hy, 93apr5120934, harder, ccr,...</td>\n",
       "      <td>[in, article, n4hy, 93apr5120934, harder, ccr,...</td>\n",
       "      <td>[in, article, n4hy, 93apr5120934, harder, ccr,...</td>\n",
       "      <td>[&lt;s&gt;, in, article, n4hy, 93apr5120934, harder,...</td>\n",
       "      <td>[&lt;s&gt;, in, article, n4hy, &lt;UNK&gt;, harder, ccr, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18789</th>\n",
       "      <td>pboxrud@magnus.acs.ohio-state.edu (Paul D Boxr...</td>\n",
       "      <td>pboxrud magnus acs ohio state edu  paul d boxr...</td>\n",
       "      <td>[pboxrud, magnus, acs, ohio, state, edu, paul,...</td>\n",
       "      <td>[pboxrud, magnus, acs, ohio, state, edu, paul,...</td>\n",
       "      <td>[pboxrud, magnus, acs, ohio, state, edu, paul,...</td>\n",
       "      <td>[&lt;s&gt;, pboxrud, magnus, acs, ohio, state, edu, ...</td>\n",
       "      <td>[&lt;s&gt;, &lt;UNK&gt;, magnus, acs, ohio, state, edu, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790</th>\n",
       "      <td>In article &lt;1993Apr23.111105.7703@ifi.uio.no&gt;,...</td>\n",
       "      <td>in article  1993apr23 111105 7703 ifi uio no  ...</td>\n",
       "      <td>[in, article, 1993apr23, 111105, 7703, ifi, ui...</td>\n",
       "      <td>[in, article, 1993apr23, 111105, 7703, ifi, ui...</td>\n",
       "      <td>[in, article, 1993apr23, NUM, NUM, ifi, uio, n...</td>\n",
       "      <td>[&lt;s&gt;, in, article, 1993apr23, NUM, NUM, ifi, u...</td>\n",
       "      <td>[&lt;s&gt;, in, article, 1993apr23, NUM, NUM, ifi, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18791</th>\n",
       "      <td>In article &lt;1rc1f3INN7rl@emx.cc.utexas.edu&gt; bi...</td>\n",
       "      <td>in article  1rc1f3inn7rl emx cc utexas edu  bi...</td>\n",
       "      <td>[in, article, 1rc1f3inn7rl, emx, cc, utexas, e...</td>\n",
       "      <td>[in, article, 1rc1f3inn7rl, emx, cc, utexas, e...</td>\n",
       "      <td>[in, article, 1rc1f3inn7rl, emx, cc, utexas, e...</td>\n",
       "      <td>[&lt;s&gt;, in, article, 1rc1f3inn7rl, emx, cc, utex...</td>\n",
       "      <td>[&lt;s&gt;, in, article, &lt;UNK&gt;, emx, cc, utexas, edu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18792</th>\n",
       "      <td>In article &lt;1993Apr26.231845.13843@digi.lonest...</td>\n",
       "      <td>in article  1993apr26 231845 13843 digi lonest...</td>\n",
       "      <td>[in, article, 1993apr26, 231845, 13843, digi, ...</td>\n",
       "      <td>[in, article, 1993apr26, 231845, 13843, digi, ...</td>\n",
       "      <td>[in, article, 1993apr26, NUM, NUM, digi, lones...</td>\n",
       "      <td>[&lt;s&gt;, in, article, 1993apr26, NUM, NUM, digi, ...</td>\n",
       "      <td>[&lt;s&gt;, in, article, 1993apr26, NUM, NUM, digi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18793</th>\n",
       "      <td>In article &lt;C64H4w.BFH@darkside.osrhe.uoknor.e...</td>\n",
       "      <td>in article  c64h4w bfh darkside osrhe uoknor e...</td>\n",
       "      <td>[in, article, c64h4w, bfh, darkside, osrhe, uo...</td>\n",
       "      <td>[in, article, c64h4w, bfh, darkside, osrhe, uo...</td>\n",
       "      <td>[in, article, c64h4w, bfh, darkside, osrhe, uo...</td>\n",
       "      <td>[&lt;s&gt;, in, article, c64h4w, bfh, darkside, osrh...</td>\n",
       "      <td>[&lt;s&gt;, in, article, &lt;UNK&gt;, bfh, darkside, osrhe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18794 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "0      Archive-name: atheism/resources Alt-atheism-ar...   \n",
       "1      Archive-name: atheism/introduction Alt-atheism...   \n",
       "2      In article <65974@mimsy.umd.edu> mangoe@cs.umd...   \n",
       "3      dmn@kepler.unh.edu (...until kings become phil...   \n",
       "4      In article <N4HY.93Apr5120934@harder.ccr-p.ida...   \n",
       "...                                                  ...   \n",
       "18789  pboxrud@magnus.acs.ohio-state.edu (Paul D Boxr...   \n",
       "18790  In article <1993Apr23.111105.7703@ifi.uio.no>,...   \n",
       "18791  In article <1rc1f3INN7rl@emx.cc.utexas.edu> bi...   \n",
       "18792  In article <1993Apr26.231845.13843@digi.lonest...   \n",
       "18793  In article <C64H4w.BFH@darkside.osrhe.uoknor.e...   \n",
       "\n",
       "                                              normalized  \\\n",
       "0      archive name  atheism resources alt atheism ar...   \n",
       "1      archive name  atheism introduction alt atheism...   \n",
       "2      in article  65974 mimsy umd edu  mangoe cs umd...   \n",
       "3      dmn kepler unh edu     until kings become phil...   \n",
       "4      in article  n4hy 93apr5120934 harder ccr p ida...   \n",
       "...                                                  ...   \n",
       "18789  pboxrud magnus acs ohio state edu  paul d boxr...   \n",
       "18790  in article  1993apr23 111105 7703 ifi uio no  ...   \n",
       "18791  in article  1rc1f3inn7rl emx cc utexas edu  bi...   \n",
       "18792  in article  1993apr26 231845 13843 digi lonest...   \n",
       "18793  in article  c64h4w bfh darkside osrhe uoknor e...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [archive, name, atheism, resources, alt, athei...   \n",
       "1      [archive, name, atheism, introduction, alt, at...   \n",
       "2      [in, article, 65974, mimsy, umd, edu, mangoe, ...   \n",
       "3      [dmn, kepler, unh, edu, until, kings, become, ...   \n",
       "4      [in, article, n4hy, 93apr5120934, harder, ccr,...   \n",
       "...                                                  ...   \n",
       "18789  [pboxrud, magnus, acs, ohio, state, edu, paul,...   \n",
       "18790  [in, article, 1993apr23, 111105, 7703, ifi, ui...   \n",
       "18791  [in, article, 1rc1f3inn7rl, emx, cc, utexas, e...   \n",
       "18792  [in, article, 1993apr26, 231845, 13843, digi, ...   \n",
       "18793  [in, article, c64h4w, bfh, darkside, osrhe, uo...   \n",
       "\n",
       "                                                  digits  \\\n",
       "0      [archive, name, atheism, resources, alt, athei...   \n",
       "1      [archive, name, atheism, introduction, alt, at...   \n",
       "2      [in, article, 65974, mimsy, umd, edu, mangoe, ...   \n",
       "3      [dmn, kepler, unh, edu, until, kings, become, ...   \n",
       "4      [in, article, n4hy, 93apr5120934, harder, ccr,...   \n",
       "...                                                  ...   \n",
       "18789  [pboxrud, magnus, acs, ohio, state, edu, paul,...   \n",
       "18790  [in, article, 1993apr23, 111105, 7703, ifi, ui...   \n",
       "18791  [in, article, 1rc1f3inn7rl, emx, cc, utexas, e...   \n",
       "18792  [in, article, 1993apr26, 231845, 13843, digi, ...   \n",
       "18793  [in, article, c64h4w, bfh, darkside, osrhe, uo...   \n",
       "\n",
       "                                             replacement  \\\n",
       "0      [archive, name, atheism, resources, alt, athei...   \n",
       "1      [archive, name, atheism, introduction, alt, at...   \n",
       "2      [in, article, NUM, mimsy, umd, edu, mangoe, cs...   \n",
       "3      [dmn, kepler, unh, edu, until, kings, become, ...   \n",
       "4      [in, article, n4hy, 93apr5120934, harder, ccr,...   \n",
       "...                                                  ...   \n",
       "18789  [pboxrud, magnus, acs, ohio, state, edu, paul,...   \n",
       "18790  [in, article, 1993apr23, NUM, NUM, ifi, uio, n...   \n",
       "18791  [in, article, 1rc1f3inn7rl, emx, cc, utexas, e...   \n",
       "18792  [in, article, 1993apr26, NUM, NUM, digi, lones...   \n",
       "18793  [in, article, c64h4w, bfh, darkside, osrhe, uo...   \n",
       "\n",
       "                                                sentence  \\\n",
       "0      [<s>, archive, name, atheism, resources, alt, ...   \n",
       "1      [<s>, archive, name, atheism, introduction, al...   \n",
       "2      [<s>, in, article, NUM, mimsy, umd, edu, mango...   \n",
       "3      [<s>, dmn, kepler, unh, edu, until, kings, bec...   \n",
       "4      [<s>, in, article, n4hy, 93apr5120934, harder,...   \n",
       "...                                                  ...   \n",
       "18789  [<s>, pboxrud, magnus, acs, ohio, state, edu, ...   \n",
       "18790  [<s>, in, article, 1993apr23, NUM, NUM, ifi, u...   \n",
       "18791  [<s>, in, article, 1rc1f3inn7rl, emx, cc, utex...   \n",
       "18792  [<s>, in, article, 1993apr26, NUM, NUM, digi, ...   \n",
       "18793  [<s>, in, article, c64h4w, bfh, darkside, osrh...   \n",
       "\n",
       "                                                  unique  \n",
       "0      [<s>, archive, name, atheism, resources, alt, ...  \n",
       "1      [<s>, archive, name, atheism, introduction, al...  \n",
       "2      [<s>, in, article, NUM, mimsy, umd, edu, mango...  \n",
       "3      [<s>, dmn, kepler, unh, edu, until, kings, bec...  \n",
       "4      [<s>, in, article, n4hy, <UNK>, harder, ccr, p...  \n",
       "...                                                  ...  \n",
       "18789  [<s>, <UNK>, magnus, acs, ohio, state, edu, pa...  \n",
       "18790  [<s>, in, article, 1993apr23, NUM, NUM, ifi, u...  \n",
       "18791  [<s>, in, article, <UNK>, emx, cc, utexas, edu...  \n",
       "18792  [<s>, in, article, 1993apr26, NUM, NUM, digi, ...  \n",
       "18793  [<s>, in, article, <UNK>, bfh, darkside, osrhe...  \n",
       "\n",
       "[18794 rows x 7 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_20n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESO DE TOKENIZADO PARA DATOS BAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizó el mismo proceso de tokenización de los datos 20N, en este caso sólo se utilizo el llamado de funciones puesto a que las funciones ya fueron creadas para los datos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bac = pd.read_csv(\"bac_unified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>profession</th>\n",
       "      <th>zodiac_sign</th>\n",
       "      <th>date</th>\n",
       "      <th>blog_content</th>\n",
       "      <th>number_of_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>2004-05-31</td>\n",
       "      <td>Well, everyone got up and going this morning. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>2004-05-29</td>\n",
       "      <td>My four-year old never stops talking.  She'll ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>2004-05-28</td>\n",
       "      <td>Actually it's not raining yet, but I bought 15...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>2004-06-21</td>\n",
       "      <td>My 20th high school  urlLink reunion  is this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>2004-06-18</td>\n",
       "      <td>We always have pizza on Friday nights.  It tak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331396</th>\n",
       "      <td>999503</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2004-07-05</td>\n",
       "      <td>Chillin to some groove salad, studying BGP con...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331397</th>\n",
       "      <td>999503</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2004-07-04</td>\n",
       "      <td>Today we celebrate our independence day.    In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331398</th>\n",
       "      <td>999503</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2004-07-03</td>\n",
       "      <td>Ugh, I think I have allergies...  My nose has ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331399</th>\n",
       "      <td>999503</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2004-07-02</td>\n",
       "      <td>\"Science is like sex; occasionally something p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331400</th>\n",
       "      <td>999503</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2004-07-01</td>\n",
       "      <td>urlLink Dog toy or marital aid   I managed 10/...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331401 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  gender  age profession zodiac_sign        date  \\\n",
       "0       1000331  female   37     indUnk         Leo  2004-05-31   \n",
       "1       1000331  female   37     indUnk         Leo  2004-05-29   \n",
       "2       1000331  female   37     indUnk         Leo  2004-05-28   \n",
       "3       1000331  female   37     indUnk         Leo  2004-06-21   \n",
       "4       1000331  female   37     indUnk         Leo  2004-06-18   \n",
       "...         ...     ...  ...        ...         ...         ...   \n",
       "331396   999503    male   25   Internet      Cancer  2004-07-05   \n",
       "331397   999503    male   25   Internet      Cancer  2004-07-04   \n",
       "331398   999503    male   25   Internet      Cancer  2004-07-03   \n",
       "331399   999503    male   25   Internet      Cancer  2004-07-02   \n",
       "331400   999503    male   25   Internet      Cancer  2004-07-01   \n",
       "\n",
       "                                             blog_content  number_of_posts  \n",
       "0       Well, everyone got up and going this morning. ...                1  \n",
       "1       My four-year old never stops talking.  She'll ...                1  \n",
       "2       Actually it's not raining yet, but I bought 15...                4  \n",
       "3       My 20th high school  urlLink reunion  is this ...                1  \n",
       "4       We always have pizza on Friday nights.  It tak...                1  \n",
       "...                                                   ...              ...  \n",
       "331396  Chillin to some groove salad, studying BGP con...                1  \n",
       "331397  Today we celebrate our independence day.    In...                1  \n",
       "331398  Ugh, I think I have allergies...  My nose has ...                1  \n",
       "331399  \"Science is like sex; occasionally something p...                1  \n",
       "331400  urlLink Dog toy or marital aid   I managed 10/...                2  \n",
       "\n",
       "[331401 rows x 8 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_bac = df_bac[['blog_content']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversión de texto del archivo BAC como strings para evitar errores en futuros pasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/3623974741.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['blog_content'] = body_bac[['blog_content']].astype(str)\n"
     ]
    }
   ],
   "source": [
    "body_bac['blog_content'] = body_bac[['blog_content']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blog_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, everyone got up and going this morning. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My four-year old never stops talking.  She'll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Actually it's not raining yet, but I bought 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My 20th high school  urlLink reunion  is this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We always have pizza on Friday nights.  It tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331396</th>\n",
       "      <td>Chillin to some groove salad, studying BGP con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331397</th>\n",
       "      <td>Today we celebrate our independence day.    In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331398</th>\n",
       "      <td>Ugh, I think I have allergies...  My nose has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331399</th>\n",
       "      <td>\"Science is like sex; occasionally something p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331400</th>\n",
       "      <td>urlLink Dog toy or marital aid   I managed 10/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331401 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             blog_content\n",
       "0       Well, everyone got up and going this morning. ...\n",
       "1       My four-year old never stops talking.  She'll ...\n",
       "2       Actually it's not raining yet, but I bought 15...\n",
       "3       My 20th high school  urlLink reunion  is this ...\n",
       "4       We always have pizza on Friday nights.  It tak...\n",
       "...                                                   ...\n",
       "331396  Chillin to some groove salad, studying BGP con...\n",
       "331397  Today we celebrate our independence day.    In...\n",
       "331398  Ugh, I think I have allergies...  My nose has ...\n",
       "331399  \"Science is like sex; occasionally something p...\n",
       "331400  urlLink Dog toy or marital aid   I managed 10/...\n",
       "\n",
       "[331401 rows x 1 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conjunto de oraciones\n",
    "body_bac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica la misma función de normalización que se utilizó para datos 20N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/2090022200.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['normalized'] = body_bac['blog_content'].apply(normalize_text)\n"
     ]
    }
   ],
   "source": [
    "body_bac['normalized'] = body_bac['blog_content'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica word_tokenize de la librería nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/1310342155.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['tokenized'] = body_bac['normalized'].apply(word_tokenize)\n"
     ]
    }
   ],
   "source": [
    "body_bac['tokenized'] = body_bac['normalized'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica el reemplazo de palabras a dígitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/757422033.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['digits'] = body_bac['tokenized'].apply(lambda tokens: [words_to_numbers(token) for token in tokens])\n"
     ]
    }
   ],
   "source": [
    "body_bac['digits'] = body_bac['tokenized'].apply(lambda tokens: [words_to_numbers(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica el reemplazo de dígitos al caracter NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/1313792504.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['replacement'] = body_bac['digits'].apply(lambda tokens: [replace_digits(token) for token in tokens])\n"
     ]
    }
   ],
   "source": [
    "body_bac['replacement'] = body_bac['digits'].apply(lambda tokens: [replace_digits(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se añade <s> al comienzo de cada frase y </s> al término de cada frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/4251335818.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['sentence'] = body_bac['replacement'].apply(lambda tokens: ['<s>'] + tokens + ['</s>'])\n"
     ]
    }
   ],
   "source": [
    "body_bac['sentence'] = body_bac['replacement'].apply(lambda tokens: ['<s>'] + tokens + ['</s>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica el mismo proceso para el reemplazo de tokens únicos en todo el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = [token for tokens in body_bac['sentence'] for token in tokens]\n",
    "token_freq = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/462386146.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['unique'] = body_bac['sentence'].apply(lambda tokens: replace_unique_tokens(tokens, token_freq))\n"
     ]
    }
   ],
   "source": [
    "body_bac['unique'] = body_bac['sentence'].apply(lambda tokens: replace_unique_tokens(tokens, token_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se exportan los datos a un dataframe único en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bac = pd.DataFrame(body_bac['unique'].apply(lambda tokens: ' '.join(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bac.to_csv(\"bac_tokenized.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIVISIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizó la librería train_test_split de scikit-learn para realizar la división aleatoria de datos, se hizo la división correspondiente de 80% para entrenamiento y 20% para prueba para ambos archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIVISIÓN DE DATOS - 20N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lectura de archivo tokenizadoo\n",
    "df_20n = pd.read_csv(\"20n_tokenized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de datos 80% - 20%\n",
    "train_20n, test_20n = train_test_split(df_20n, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se exportan los datos obtenidos de la división a un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_20n.to_csv(\"20N_01_training.csv\")\n",
    "test_20n.to_csv(\"20N_01_testing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIVISIÓN DE DATOS - BAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lectura de archivoo\n",
    "df_bac = pd.read_csv(\"bac_tokenized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de datos 80% - 20%\n",
    "train_bac, test_bac = train_test_split(df_bac, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se exportan los datos obtenidos de la división a un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bac.to_csv(\"BAC_01_training.csv\")\n",
    "test_bac.to_csv(\"BAC_01_testing.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
