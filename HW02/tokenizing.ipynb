{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "from text_to_num import text2num\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARA DATOS 20N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20n = pd.read_csv(\"20N_unified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_20n = df_20n[['body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    return text\n",
    "\n",
    "def words_to_numbers(token):\n",
    "    try:\n",
    "        return str(text2num(token,'en'))\n",
    "    except ValueError:\n",
    "        return token\n",
    "\n",
    "def replace_digits(token):\n",
    "    if token.isdigit():\n",
    "        return 'NUM'\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/3604201721.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_20n['normalized'] = body_20n['body'].apply(normalize_text)\n"
     ]
    }
   ],
   "source": [
    "body_20n['normalized'] = body_20n['body'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/814313017.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_20n['tokenized'] = body_20n['normalized'].apply(word_tokenize)\n"
     ]
    }
   ],
   "source": [
    "body_20n['tokenized'] = body_20n['normalized'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/282450380.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_20n['digits'] = body_20n['tokenized'].apply(lambda tokens: [words_to_numbers(token) for token in tokens])\n"
     ]
    }
   ],
   "source": [
    "body_20n['digits'] = body_20n['tokenized'].apply(lambda tokens: [words_to_numbers(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_20n['replacement'] = body_20n['digits'].apply(lambda tokens: [replace_digits(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_20n['sentence'] = body_20n['replacement'].apply(lambda tokens: ['<s>'] + tokens + ['</s>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = [token for tokens in body_20n['sentence'] for token in tokens]\n",
    "token_freq = Counter(all_tokens)\n",
    "\n",
    "def replace_unique_tokens(tokens, freq_dict):\n",
    "    return [token if freq_dict[token] > 1 else '<UNK>' for token in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_20n['unique'] = body_20n['sentence'].apply(lambda tokens: replace_unique_tokens(tokens, token_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_20n = pd.DataFrame(body_20n['unique'].apply(lambda tokens: ' '.join(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_20n.to_csv(\"20n_tokenized.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>normalized</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>digits</th>\n",
       "      <th>replacement</th>\n",
       "      <th>sentence</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Archive-name: atheism/resources Alt-atheism-ar...</td>\n",
       "      <td>archive name  atheism resources alt atheism ar...</td>\n",
       "      <td>[archive, name, atheism, resources, alt, athei...</td>\n",
       "      <td>[archive, name, atheism, resources, alt, athei...</td>\n",
       "      <td>[archive, name, atheism, resources, alt, athei...</td>\n",
       "      <td>[&lt;s&gt;, archive, name, atheism, resources, alt, ...</td>\n",
       "      <td>[&lt;s&gt;, archive, name, atheism, resources, alt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Archive-name: atheism/introduction Alt-atheism...</td>\n",
       "      <td>archive name  atheism introduction alt atheism...</td>\n",
       "      <td>[archive, name, atheism, introduction, alt, at...</td>\n",
       "      <td>[archive, name, atheism, introduction, alt, at...</td>\n",
       "      <td>[archive, name, atheism, introduction, alt, at...</td>\n",
       "      <td>[&lt;s&gt;, archive, name, atheism, introduction, al...</td>\n",
       "      <td>[&lt;s&gt;, archive, name, atheism, introduction, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In article &lt;65974@mimsy.umd.edu&gt; mangoe@cs.umd...</td>\n",
       "      <td>in article  65974 mimsy umd edu  mangoe cs umd...</td>\n",
       "      <td>[in, article, 65974, mimsy, umd, edu, mangoe, ...</td>\n",
       "      <td>[in, article, 65974, mimsy, umd, edu, mangoe, ...</td>\n",
       "      <td>[in, article, NUM, mimsy, umd, edu, mangoe, cs...</td>\n",
       "      <td>[&lt;s&gt;, in, article, NUM, mimsy, umd, edu, mango...</td>\n",
       "      <td>[&lt;s&gt;, in, article, NUM, mimsy, umd, edu, mango...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dmn@kepler.unh.edu (...until kings become phil...</td>\n",
       "      <td>dmn kepler unh edu     until kings become phil...</td>\n",
       "      <td>[dmn, kepler, unh, edu, until, kings, become, ...</td>\n",
       "      <td>[dmn, kepler, unh, edu, until, kings, become, ...</td>\n",
       "      <td>[dmn, kepler, unh, edu, until, kings, become, ...</td>\n",
       "      <td>[&lt;s&gt;, dmn, kepler, unh, edu, until, kings, bec...</td>\n",
       "      <td>[&lt;s&gt;, dmn, kepler, unh, edu, until, kings, bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In article &lt;N4HY.93Apr5120934@harder.ccr-p.ida...</td>\n",
       "      <td>in article  n4hy 93apr5120934 harder ccr p ida...</td>\n",
       "      <td>[in, article, n4hy, 93apr5120934, harder, ccr,...</td>\n",
       "      <td>[in, article, n4hy, 93apr5120934, harder, ccr,...</td>\n",
       "      <td>[in, article, n4hy, 93apr5120934, harder, ccr,...</td>\n",
       "      <td>[&lt;s&gt;, in, article, n4hy, 93apr5120934, harder,...</td>\n",
       "      <td>[&lt;s&gt;, in, article, n4hy, &lt;UNK&gt;, harder, ccr, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18789</th>\n",
       "      <td>pboxrud@magnus.acs.ohio-state.edu (Paul D Boxr...</td>\n",
       "      <td>pboxrud magnus acs ohio state edu  paul d boxr...</td>\n",
       "      <td>[pboxrud, magnus, acs, ohio, state, edu, paul,...</td>\n",
       "      <td>[pboxrud, magnus, acs, ohio, state, edu, paul,...</td>\n",
       "      <td>[pboxrud, magnus, acs, ohio, state, edu, paul,...</td>\n",
       "      <td>[&lt;s&gt;, pboxrud, magnus, acs, ohio, state, edu, ...</td>\n",
       "      <td>[&lt;s&gt;, &lt;UNK&gt;, magnus, acs, ohio, state, edu, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790</th>\n",
       "      <td>In article &lt;1993Apr23.111105.7703@ifi.uio.no&gt;,...</td>\n",
       "      <td>in article  1993apr23 111105 7703 ifi uio no  ...</td>\n",
       "      <td>[in, article, 1993apr23, 111105, 7703, ifi, ui...</td>\n",
       "      <td>[in, article, 1993apr23, 111105, 7703, ifi, ui...</td>\n",
       "      <td>[in, article, 1993apr23, NUM, NUM, ifi, uio, n...</td>\n",
       "      <td>[&lt;s&gt;, in, article, 1993apr23, NUM, NUM, ifi, u...</td>\n",
       "      <td>[&lt;s&gt;, in, article, 1993apr23, NUM, NUM, ifi, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18791</th>\n",
       "      <td>In article &lt;1rc1f3INN7rl@emx.cc.utexas.edu&gt; bi...</td>\n",
       "      <td>in article  1rc1f3inn7rl emx cc utexas edu  bi...</td>\n",
       "      <td>[in, article, 1rc1f3inn7rl, emx, cc, utexas, e...</td>\n",
       "      <td>[in, article, 1rc1f3inn7rl, emx, cc, utexas, e...</td>\n",
       "      <td>[in, article, 1rc1f3inn7rl, emx, cc, utexas, e...</td>\n",
       "      <td>[&lt;s&gt;, in, article, 1rc1f3inn7rl, emx, cc, utex...</td>\n",
       "      <td>[&lt;s&gt;, in, article, &lt;UNK&gt;, emx, cc, utexas, edu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18792</th>\n",
       "      <td>In article &lt;1993Apr26.231845.13843@digi.lonest...</td>\n",
       "      <td>in article  1993apr26 231845 13843 digi lonest...</td>\n",
       "      <td>[in, article, 1993apr26, 231845, 13843, digi, ...</td>\n",
       "      <td>[in, article, 1993apr26, 231845, 13843, digi, ...</td>\n",
       "      <td>[in, article, 1993apr26, NUM, NUM, digi, lones...</td>\n",
       "      <td>[&lt;s&gt;, in, article, 1993apr26, NUM, NUM, digi, ...</td>\n",
       "      <td>[&lt;s&gt;, in, article, 1993apr26, NUM, NUM, digi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18793</th>\n",
       "      <td>In article &lt;C64H4w.BFH@darkside.osrhe.uoknor.e...</td>\n",
       "      <td>in article  c64h4w bfh darkside osrhe uoknor e...</td>\n",
       "      <td>[in, article, c64h4w, bfh, darkside, osrhe, uo...</td>\n",
       "      <td>[in, article, c64h4w, bfh, darkside, osrhe, uo...</td>\n",
       "      <td>[in, article, c64h4w, bfh, darkside, osrhe, uo...</td>\n",
       "      <td>[&lt;s&gt;, in, article, c64h4w, bfh, darkside, osrh...</td>\n",
       "      <td>[&lt;s&gt;, in, article, &lt;UNK&gt;, bfh, darkside, osrhe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18794 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "0      Archive-name: atheism/resources Alt-atheism-ar...   \n",
       "1      Archive-name: atheism/introduction Alt-atheism...   \n",
       "2      In article <65974@mimsy.umd.edu> mangoe@cs.umd...   \n",
       "3      dmn@kepler.unh.edu (...until kings become phil...   \n",
       "4      In article <N4HY.93Apr5120934@harder.ccr-p.ida...   \n",
       "...                                                  ...   \n",
       "18789  pboxrud@magnus.acs.ohio-state.edu (Paul D Boxr...   \n",
       "18790  In article <1993Apr23.111105.7703@ifi.uio.no>,...   \n",
       "18791  In article <1rc1f3INN7rl@emx.cc.utexas.edu> bi...   \n",
       "18792  In article <1993Apr26.231845.13843@digi.lonest...   \n",
       "18793  In article <C64H4w.BFH@darkside.osrhe.uoknor.e...   \n",
       "\n",
       "                                              normalized  \\\n",
       "0      archive name  atheism resources alt atheism ar...   \n",
       "1      archive name  atheism introduction alt atheism...   \n",
       "2      in article  65974 mimsy umd edu  mangoe cs umd...   \n",
       "3      dmn kepler unh edu     until kings become phil...   \n",
       "4      in article  n4hy 93apr5120934 harder ccr p ida...   \n",
       "...                                                  ...   \n",
       "18789  pboxrud magnus acs ohio state edu  paul d boxr...   \n",
       "18790  in article  1993apr23 111105 7703 ifi uio no  ...   \n",
       "18791  in article  1rc1f3inn7rl emx cc utexas edu  bi...   \n",
       "18792  in article  1993apr26 231845 13843 digi lonest...   \n",
       "18793  in article  c64h4w bfh darkside osrhe uoknor e...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [archive, name, atheism, resources, alt, athei...   \n",
       "1      [archive, name, atheism, introduction, alt, at...   \n",
       "2      [in, article, 65974, mimsy, umd, edu, mangoe, ...   \n",
       "3      [dmn, kepler, unh, edu, until, kings, become, ...   \n",
       "4      [in, article, n4hy, 93apr5120934, harder, ccr,...   \n",
       "...                                                  ...   \n",
       "18789  [pboxrud, magnus, acs, ohio, state, edu, paul,...   \n",
       "18790  [in, article, 1993apr23, 111105, 7703, ifi, ui...   \n",
       "18791  [in, article, 1rc1f3inn7rl, emx, cc, utexas, e...   \n",
       "18792  [in, article, 1993apr26, 231845, 13843, digi, ...   \n",
       "18793  [in, article, c64h4w, bfh, darkside, osrhe, uo...   \n",
       "\n",
       "                                                  digits  \\\n",
       "0      [archive, name, atheism, resources, alt, athei...   \n",
       "1      [archive, name, atheism, introduction, alt, at...   \n",
       "2      [in, article, 65974, mimsy, umd, edu, mangoe, ...   \n",
       "3      [dmn, kepler, unh, edu, until, kings, become, ...   \n",
       "4      [in, article, n4hy, 93apr5120934, harder, ccr,...   \n",
       "...                                                  ...   \n",
       "18789  [pboxrud, magnus, acs, ohio, state, edu, paul,...   \n",
       "18790  [in, article, 1993apr23, 111105, 7703, ifi, ui...   \n",
       "18791  [in, article, 1rc1f3inn7rl, emx, cc, utexas, e...   \n",
       "18792  [in, article, 1993apr26, 231845, 13843, digi, ...   \n",
       "18793  [in, article, c64h4w, bfh, darkside, osrhe, uo...   \n",
       "\n",
       "                                             replacement  \\\n",
       "0      [archive, name, atheism, resources, alt, athei...   \n",
       "1      [archive, name, atheism, introduction, alt, at...   \n",
       "2      [in, article, NUM, mimsy, umd, edu, mangoe, cs...   \n",
       "3      [dmn, kepler, unh, edu, until, kings, become, ...   \n",
       "4      [in, article, n4hy, 93apr5120934, harder, ccr,...   \n",
       "...                                                  ...   \n",
       "18789  [pboxrud, magnus, acs, ohio, state, edu, paul,...   \n",
       "18790  [in, article, 1993apr23, NUM, NUM, ifi, uio, n...   \n",
       "18791  [in, article, 1rc1f3inn7rl, emx, cc, utexas, e...   \n",
       "18792  [in, article, 1993apr26, NUM, NUM, digi, lones...   \n",
       "18793  [in, article, c64h4w, bfh, darkside, osrhe, uo...   \n",
       "\n",
       "                                                sentence  \\\n",
       "0      [<s>, archive, name, atheism, resources, alt, ...   \n",
       "1      [<s>, archive, name, atheism, introduction, al...   \n",
       "2      [<s>, in, article, NUM, mimsy, umd, edu, mango...   \n",
       "3      [<s>, dmn, kepler, unh, edu, until, kings, bec...   \n",
       "4      [<s>, in, article, n4hy, 93apr5120934, harder,...   \n",
       "...                                                  ...   \n",
       "18789  [<s>, pboxrud, magnus, acs, ohio, state, edu, ...   \n",
       "18790  [<s>, in, article, 1993apr23, NUM, NUM, ifi, u...   \n",
       "18791  [<s>, in, article, 1rc1f3inn7rl, emx, cc, utex...   \n",
       "18792  [<s>, in, article, 1993apr26, NUM, NUM, digi, ...   \n",
       "18793  [<s>, in, article, c64h4w, bfh, darkside, osrh...   \n",
       "\n",
       "                                                  unique  \n",
       "0      [<s>, archive, name, atheism, resources, alt, ...  \n",
       "1      [<s>, archive, name, atheism, introduction, al...  \n",
       "2      [<s>, in, article, NUM, mimsy, umd, edu, mango...  \n",
       "3      [<s>, dmn, kepler, unh, edu, until, kings, bec...  \n",
       "4      [<s>, in, article, n4hy, <UNK>, harder, ccr, p...  \n",
       "...                                                  ...  \n",
       "18789  [<s>, <UNK>, magnus, acs, ohio, state, edu, pa...  \n",
       "18790  [<s>, in, article, 1993apr23, NUM, NUM, ifi, u...  \n",
       "18791  [<s>, in, article, <UNK>, emx, cc, utexas, edu...  \n",
       "18792  [<s>, in, article, 1993apr26, NUM, NUM, digi, ...  \n",
       "18793  [<s>, in, article, <UNK>, bfh, darkside, osrhe...  \n",
       "\n",
       "[18794 rows x 7 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_20n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARA DATOS BAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bac = pd.read_csv(\"bac_unified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>profession</th>\n",
       "      <th>zodiac_sign</th>\n",
       "      <th>date</th>\n",
       "      <th>blog_content</th>\n",
       "      <th>number_of_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>2004-05-31</td>\n",
       "      <td>Well, everyone got up and going this morning. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>2004-05-29</td>\n",
       "      <td>My four-year old never stops talking.  She'll ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>2004-05-28</td>\n",
       "      <td>Actually it's not raining yet, but I bought 15...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>2004-06-21</td>\n",
       "      <td>My 20th high school  urlLink reunion  is this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000331</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Leo</td>\n",
       "      <td>2004-06-18</td>\n",
       "      <td>We always have pizza on Friday nights.  It tak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331396</th>\n",
       "      <td>999503</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2004-07-05</td>\n",
       "      <td>Chillin to some groove salad, studying BGP con...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331397</th>\n",
       "      <td>999503</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2004-07-04</td>\n",
       "      <td>Today we celebrate our independence day.    In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331398</th>\n",
       "      <td>999503</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2004-07-03</td>\n",
       "      <td>Ugh, I think I have allergies...  My nose has ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331399</th>\n",
       "      <td>999503</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2004-07-02</td>\n",
       "      <td>\"Science is like sex; occasionally something p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331400</th>\n",
       "      <td>999503</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2004-07-01</td>\n",
       "      <td>urlLink Dog toy or marital aid   I managed 10/...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331401 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  gender  age profession zodiac_sign        date  \\\n",
       "0       1000331  female   37     indUnk         Leo  2004-05-31   \n",
       "1       1000331  female   37     indUnk         Leo  2004-05-29   \n",
       "2       1000331  female   37     indUnk         Leo  2004-05-28   \n",
       "3       1000331  female   37     indUnk         Leo  2004-06-21   \n",
       "4       1000331  female   37     indUnk         Leo  2004-06-18   \n",
       "...         ...     ...  ...        ...         ...         ...   \n",
       "331396   999503    male   25   Internet      Cancer  2004-07-05   \n",
       "331397   999503    male   25   Internet      Cancer  2004-07-04   \n",
       "331398   999503    male   25   Internet      Cancer  2004-07-03   \n",
       "331399   999503    male   25   Internet      Cancer  2004-07-02   \n",
       "331400   999503    male   25   Internet      Cancer  2004-07-01   \n",
       "\n",
       "                                             blog_content  number_of_posts  \n",
       "0       Well, everyone got up and going this morning. ...                1  \n",
       "1       My four-year old never stops talking.  She'll ...                1  \n",
       "2       Actually it's not raining yet, but I bought 15...                4  \n",
       "3       My 20th high school  urlLink reunion  is this ...                1  \n",
       "4       We always have pizza on Friday nights.  It tak...                1  \n",
       "...                                                   ...              ...  \n",
       "331396  Chillin to some groove salad, studying BGP con...                1  \n",
       "331397  Today we celebrate our independence day.    In...                1  \n",
       "331398  Ugh, I think I have allergies...  My nose has ...                1  \n",
       "331399  \"Science is like sex; occasionally something p...                1  \n",
       "331400  urlLink Dog toy or marital aid   I managed 10/...                2  \n",
       "\n",
       "[331401 rows x 8 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_bac = df_bac[['blog_content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/3623974741.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['blog_content'] = body_bac[['blog_content']].astype(str)\n"
     ]
    }
   ],
   "source": [
    "body_bac['blog_content'] = body_bac[['blog_content']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blog_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, everyone got up and going this morning. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My four-year old never stops talking.  She'll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Actually it's not raining yet, but I bought 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My 20th high school  urlLink reunion  is this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We always have pizza on Friday nights.  It tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331396</th>\n",
       "      <td>Chillin to some groove salad, studying BGP con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331397</th>\n",
       "      <td>Today we celebrate our independence day.    In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331398</th>\n",
       "      <td>Ugh, I think I have allergies...  My nose has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331399</th>\n",
       "      <td>\"Science is like sex; occasionally something p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331400</th>\n",
       "      <td>urlLink Dog toy or marital aid   I managed 10/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331401 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             blog_content\n",
       "0       Well, everyone got up and going this morning. ...\n",
       "1       My four-year old never stops talking.  She'll ...\n",
       "2       Actually it's not raining yet, but I bought 15...\n",
       "3       My 20th high school  urlLink reunion  is this ...\n",
       "4       We always have pizza on Friday nights.  It tak...\n",
       "...                                                   ...\n",
       "331396  Chillin to some groove salad, studying BGP con...\n",
       "331397  Today we celebrate our independence day.    In...\n",
       "331398  Ugh, I think I have allergies...  My nose has ...\n",
       "331399  \"Science is like sex; occasionally something p...\n",
       "331400  urlLink Dog toy or marital aid   I managed 10/...\n",
       "\n",
       "[331401 rows x 1 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/2090022200.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['normalized'] = body_bac['blog_content'].apply(normalize_text)\n"
     ]
    }
   ],
   "source": [
    "body_bac['normalized'] = body_bac['blog_content'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/1310342155.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['tokenized'] = body_bac['normalized'].apply(word_tokenize)\n"
     ]
    }
   ],
   "source": [
    "body_bac['tokenized'] = body_bac['normalized'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blog_content</th>\n",
       "      <th>normalized</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, everyone got up and going this morning. ...</td>\n",
       "      <td>well  everyone got up and going this morning  ...</td>\n",
       "      <td>[well, everyone, got, up, and, going, this, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My four-year old never stops talking.  She'll ...</td>\n",
       "      <td>my four year old never stops talking   she ll ...</td>\n",
       "      <td>[my, four, year, old, never, stops, talking, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Actually it's not raining yet, but I bought 15...</td>\n",
       "      <td>actually it s not raining yet  but i bought 15...</td>\n",
       "      <td>[actually, it, s, not, raining, yet, but, i, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My 20th high school  urlLink reunion  is this ...</td>\n",
       "      <td>my 20th high school  urllink reunion  is this ...</td>\n",
       "      <td>[my, 20th, high, school, urllink, reunion, is,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We always have pizza on Friday nights.  It tak...</td>\n",
       "      <td>we always have pizza on friday nights   it tak...</td>\n",
       "      <td>[we, always, have, pizza, on, friday, nights, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331396</th>\n",
       "      <td>Chillin to some groove salad, studying BGP con...</td>\n",
       "      <td>chillin to some groove salad  studying bgp con...</td>\n",
       "      <td>[chillin, to, some, groove, salad, studying, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331397</th>\n",
       "      <td>Today we celebrate our independence day.    In...</td>\n",
       "      <td>today we celebrate our independence day     in...</td>\n",
       "      <td>[today, we, celebrate, our, independence, day,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331398</th>\n",
       "      <td>Ugh, I think I have allergies...  My nose has ...</td>\n",
       "      <td>ugh  i think i have allergies     my nose has ...</td>\n",
       "      <td>[ugh, i, think, i, have, allergies, my, nose, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331399</th>\n",
       "      <td>\"Science is like sex; occasionally something p...</td>\n",
       "      <td>science is like sex  occasionally something p...</td>\n",
       "      <td>[science, is, like, sex, occasionally, somethi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331400</th>\n",
       "      <td>urlLink Dog toy or marital aid   I managed 10/...</td>\n",
       "      <td>urllink dog toy or marital aid   i managed 10 ...</td>\n",
       "      <td>[urllink, dog, toy, or, marital, aid, i, manag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331401 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             blog_content  \\\n",
       "0       Well, everyone got up and going this morning. ...   \n",
       "1       My four-year old never stops talking.  She'll ...   \n",
       "2       Actually it's not raining yet, but I bought 15...   \n",
       "3       My 20th high school  urlLink reunion  is this ...   \n",
       "4       We always have pizza on Friday nights.  It tak...   \n",
       "...                                                   ...   \n",
       "331396  Chillin to some groove salad, studying BGP con...   \n",
       "331397  Today we celebrate our independence day.    In...   \n",
       "331398  Ugh, I think I have allergies...  My nose has ...   \n",
       "331399  \"Science is like sex; occasionally something p...   \n",
       "331400  urlLink Dog toy or marital aid   I managed 10/...   \n",
       "\n",
       "                                               normalized  \\\n",
       "0       well  everyone got up and going this morning  ...   \n",
       "1       my four year old never stops talking   she ll ...   \n",
       "2       actually it s not raining yet  but i bought 15...   \n",
       "3       my 20th high school  urllink reunion  is this ...   \n",
       "4       we always have pizza on friday nights   it tak...   \n",
       "...                                                   ...   \n",
       "331396  chillin to some groove salad  studying bgp con...   \n",
       "331397  today we celebrate our independence day     in...   \n",
       "331398  ugh  i think i have allergies     my nose has ...   \n",
       "331399   science is like sex  occasionally something p...   \n",
       "331400  urllink dog toy or marital aid   i managed 10 ...   \n",
       "\n",
       "                                                tokenized  \n",
       "0       [well, everyone, got, up, and, going, this, mo...  \n",
       "1       [my, four, year, old, never, stops, talking, s...  \n",
       "2       [actually, it, s, not, raining, yet, but, i, b...  \n",
       "3       [my, 20th, high, school, urllink, reunion, is,...  \n",
       "4       [we, always, have, pizza, on, friday, nights, ...  \n",
       "...                                                   ...  \n",
       "331396  [chillin, to, some, groove, salad, studying, b...  \n",
       "331397  [today, we, celebrate, our, independence, day,...  \n",
       "331398  [ugh, i, think, i, have, allergies, my, nose, ...  \n",
       "331399  [science, is, like, sex, occasionally, somethi...  \n",
       "331400  [urllink, dog, toy, or, marital, aid, i, manag...  \n",
       "\n",
       "[331401 rows x 3 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/757422033.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['digits'] = body_bac['tokenized'].apply(lambda tokens: [words_to_numbers(token) for token in tokens])\n"
     ]
    }
   ],
   "source": [
    "body_bac['digits'] = body_bac['tokenized'].apply(lambda tokens: [words_to_numbers(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/1313792504.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['replacement'] = body_bac['digits'].apply(lambda tokens: [replace_digits(token) for token in tokens])\n"
     ]
    }
   ],
   "source": [
    "body_bac['replacement'] = body_bac['digits'].apply(lambda tokens: [replace_digits(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/4251335818.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['sentence'] = body_bac['replacement'].apply(lambda tokens: ['<s>'] + tokens + ['</s>'])\n"
     ]
    }
   ],
   "source": [
    "body_bac['sentence'] = body_bac['replacement'].apply(lambda tokens: ['<s>'] + tokens + ['</s>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = [token for tokens in body_bac['sentence'] for token in tokens]\n",
    "token_freq = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/dt9fh71s1yq44ph9g2dysl4r0000gn/T/ipykernel_77944/462386146.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  body_bac['unique'] = body_bac['sentence'].apply(lambda tokens: replace_unique_tokens(tokens, token_freq))\n"
     ]
    }
   ],
   "source": [
    "body_bac['unique'] = body_bac['sentence'].apply(lambda tokens: replace_unique_tokens(tokens, token_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bac = pd.DataFrame(body_bac['unique'].apply(lambda tokens: ' '.join(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bac.to_csv(\"bac_tokenized.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
