{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de bibliotecas, funciones necesarias y carga de modelos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "\n",
    "def crearDefaultdictCounter():\n",
    "    \"\"\"\n",
    "    Crea un defaultdict de Counter, para utilizar en el modelo de trigramas\n",
    "    \n",
    "    Retorna:\n",
    "    defaultdict(Counter): Un defaultdict que retorna un Counter por defecto\n",
    "    \"\"\"\n",
    "    return defaultdict(Counter)\n",
    "\n",
    "def cargarModelo(nombreArchivo):\n",
    "    \"\"\"\n",
    "    Carga un modelo desde un archivo pickle.\n",
    "    \n",
    "    Parámetros:\n",
    "    - nombreArchivo (str): Nombre del archivo desde donde se cargará el modelo\n",
    "    \n",
    "    Retorna:\n",
    "    - modelo: El modelo cargado.\n",
    "    \"\"\"\n",
    "    with open(nombreArchivo, 'rb') as archivo:\n",
    "        modelo = pickle.load(archivo)\n",
    "    return modelo\n",
    "\n",
    "def separarOraciones(datos):\n",
    "    \"\"\"\n",
    "    Separar las oraciones de un DataFrame a partir de la columna 'unique'\n",
    "    \n",
    "    Parámetros:\n",
    "    - datos (pd.DataFrame): DataFrame que contiene una columna 'unique' con las oraciones\n",
    "    \n",
    "    Retorna\n",
    "    - list: Lista de oraciones tokenizadas, donde cada oración es una lista de tokens\n",
    "    \"\"\"\n",
    "    oracionesSeparadas = []\n",
    "    for oracion in datos['unique']:\n",
    "        tokens = oracion.split()  \n",
    "        oracionesSeparadas.append(tokens)\n",
    "    return oracionesSeparadas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20N\n",
    "unigrama20N = cargarModelo('20N_01_unigramas.pkl')\n",
    "bigrama20N = cargarModelo('20N_01_bigramas.pkl')\n",
    "trigrama20N = cargarModelo('20N_01_trigramas.pkl')\n",
    "\n",
    "#BAC\n",
    "unigramaBAC = cargarModelo('BAC_01_unigramas.pkl')\n",
    "bigramaBAC = cargarModelo('BAC_01_bigramas.pkl')\n",
    "trigramaBAC = cargarModelo('BAC_01_trigramas.pkl')\n",
    "\n",
    "# testing csvs\n",
    "datos20N_test = pd.read_csv('20N_01_testing.csv')\n",
    "datosBAC_test = pd.read_csv('BAC_01_testing.csv')\n",
    "oracionesSeparadas20N_test = separarOraciones(datos20N_test)\n",
    "oracionesSeparadasBAC_test = separarOraciones(datosBAC_test)\n",
    "\n",
    "tamanoVocabulario20N = len(unigrama20N)\n",
    "tamanoVocabularioBAC = len(unigramaBAC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de Perplejidad para los Modelos N-Grama\n",
    "\n",
    "Para wvaluar el rendimiento de nuestros modelos de lenguaje, calculamos la **perplejidad** de cada uno sobre el conjunto de prueba. La perplejidad es una medida que indica qué tan bien un modelo predice una muestra. Un valor de perplejidad más bajo sugiere un modelo mejor\n",
    "\n",
    "Definimos funciones para calcular la perplejidad de los modelos de **unigramas**, **bigramas** y **trigramas**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularPerplejidadUnigrama(modeloUnigrama, oracionesSeparadas, tamanoVocabulario):\n",
    "    \"\"\"\n",
    "    Calcula la perplejidad de un modelo de unigramas dado un conjunto de oraciones tokenizadas\n",
    "\n",
    "    Parámetros:\n",
    "    - modeloUnigrama (Counter): Modelo de unigramas\n",
    "    - oracionesSeparadas (list): Lista de oraciones tokenizadas\n",
    "    - tamanoVocabulario (int): Tamaño del vocabulario del modelo\n",
    "\n",
    "    Retorna:\n",
    "    - float: Perplejidad del modelo sobre el conjunto de oracione\n",
    "    \"\"\"\n",
    "    totalLogProb = 0\n",
    "    totalPalabras = 0\n",
    "    totalFrecuencia = sum(modeloUnigrama.values())\n",
    "\n",
    "    for oracion in oracionesSeparadas:\n",
    "        for palabra in oracion:\n",
    "            frecuencia = modeloUnigrama.get(palabra, 0)\n",
    "            probabilidad = (frecuencia + 1) / (totalFrecuencia + tamanoVocabulario)\n",
    "            logProb = math.log(probabilidad)\n",
    "            totalLogProb += logProb\n",
    "            totalPalabras += 1\n",
    "\n",
    "    perplejidad = math.exp(-totalLogProb / totalPalabras)\n",
    "    return perplejidad\n",
    "\n",
    "def calcularPerplejidadBigrama(modeloBigrama, modeloUnigrama, oracionesSeparadas, tamanoVocabulario):\n",
    "    \"\"\"\n",
    "    Calcula la perplejidad de un modelo de bigramas dado un conjunto de oraciones tokenizadas\n",
    "\n",
    "    Parámetros:\n",
    "    - modeloBigrama (defaultdict(Counter)): Modelo de bigramas\n",
    "    - modeloUnigrama (Counter): Modelo de unigramas\n",
    "    - oracionesSeparadas (list): Lista de oraciones tokenizqdas\n",
    "    - tamanoVocabulario (int): Tamaño del vocabulario del modelo\n",
    "\n",
    "    Retorna:\n",
    "    - float: Perplejidad del modelo sobre el conjunto de oraciones\n",
    "    \"\"\"\n",
    "    totalLogProb = 0\n",
    "    totalPalabras = 0\n",
    "\n",
    "    for oracion in oracionesSeparadas:\n",
    "        for i in range(len(oracion) - 1):\n",
    "            palabra1 = oracion[i]\n",
    "            palabra2 = oracion[i+1]\n",
    "\n",
    "            frecuenciaBigram = modeloBigrama.get(palabra1, {}).get(palabra2, 0)\n",
    "            frecuenciaUnigram = modeloUnigrama.get(palabra1, 0)\n",
    "            probabilidad = (frecuenciaBigram + 1) / (frecuenciaUnigram + tamanoVocabulario)\n",
    "            logProb = math.log(probabilidad)\n",
    "            totalLogProb += logProb\n",
    "            totalPalabras += 1\n",
    "\n",
    "    perplejidad = math.exp(-totalLogProb / totalPalabras)\n",
    "    return perplejidad\n",
    "\n",
    "def calcularPerplejidadTrigrama(modeloTrigrama, modeloBigrama, oracionesSeparadas, tamanoVocabulario):\n",
    "    \"\"\"\n",
    "    Calcula la perplejidad de un modelo de trigramas dado un conjunto de oraciones tokenizadas\n",
    "\n",
    "    Parámetros:\n",
    "    - modeloTrigrama (defaultdict): Modelo de trigramas\n",
    "    - modeloBigrama (defaultdict(Counter)): Modelo de bigramas\n",
    "    - oracionesSeparadas (list): Lista de oraciones tokenizadas\n",
    "\n",
    "    Retorna:\n",
    "    - float: Perplejidad del modelo sobre el conjunto de oraciones\n",
    "    \"\"\"\n",
    "    totalLogProb = 0\n",
    "    totalPalabras = 0\n",
    "\n",
    "    for oracion in oracionesSeparadas:\n",
    "        for i in range(len(oracion) - 2):\n",
    "            palabra1 = oracion[i]\n",
    "            palabra2 = oracion[i+1]\n",
    "            palabra3 = oracion[i+2]\n",
    "\n",
    "            frecuenciaTrigram = modeloTrigrama.get(palabra1, {}).get(palabra2, {}).get(palabra3, 0)\n",
    "            frecuenciaBigram = modeloBigrama.get(palabra1, {}).get(palabra2, 0)\n",
    "            probabilidad = (frecuenciaTrigram + 1) / (frecuenciaBigram + tamanoVocabulario)\n",
    "            logProb = math.log(probabilidad)\n",
    "            totalLogProb += logProb\n",
    "            totalPalabras += 1\n",
    "\n",
    "    perplejidad = math.exp(-totalLogProb / totalPalabras)\n",
    "    return perplejidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de la Perplejidad\n",
    "\n",
    "Después de calcular las perplejidades, organizamos los resultados en una tabla \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplejidades calculadas:\n",
      "\n",
      "Modelo Unigrama 20N: 1514.136822471852\n",
      "Modelo Bigrama 20N: 3119.2630248796004\n",
      "Modelo Trigrama 20N: 18635.35423630719\n",
      "\n",
      "Modelo Unigrama BAC: 1123.649051033008\n",
      "Modelo Bigrama BAC: 1451.2946974119318\n",
      "Modelo Trigrama BAC: 21615.39448207005\n"
     ]
    }
   ],
   "source": [
    "# Calcular perplejidad para 20N\n",
    "perplejidadUnigrama20N = calcularPerplejidadUnigrama(unigrama20N, oracionesSeparadas20N_test, tamanoVocabulario20N)\n",
    "perplejidadBigrama20N = calcularPerplejidadBigrama(bigrama20N, unigrama20N, oracionesSeparadas20N_test, tamanoVocabulario20N)\n",
    "perplejidadTrigrama20N = calcularPerplejidadTrigrama(trigrama20N, bigrama20N, oracionesSeparadas20N_test, tamanoVocabulario20N)\n",
    "\n",
    "# Calcular perplejidad para BAC\n",
    "perplejidadUnigramaBAC = calcularPerplejidadUnigrama(unigramaBAC, oracionesSeparadasBAC_test, tamanoVocabularioBAC)\n",
    "perplejidadBigramaBAC = calcularPerplejidadBigrama(bigramaBAC, unigramaBAC, oracionesSeparadasBAC_test, tamanoVocabularioBAC)\n",
    "perplejidadTrigramaBAC = calcularPerplejidadTrigrama(trigramaBAC, bigramaBAC, oracionesSeparadasBAC_test, tamanoVocabularioBAC)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Perplejidades calculadas:\\n\")\n",
    "print(f\"Modelo Unigrama 20N: {perplejidadUnigrama20N}\")\n",
    "print(f\"Modelo Bigrama 20N: {perplejidadBigrama20N}\")\n",
    "print(f\"Modelo Trigrama 20N: {perplejidadTrigrama20N}\\n\")\n",
    "\n",
    "print(f\"Modelo Unigrama BAC: {perplejidadUnigramaBAC}\")\n",
    "print(f\"Modelo Bigrama BAC: {perplejidadBigramaBAC}\")\n",
    "print(f\"Modelo Trigrama BAC: {perplejidadTrigramaBAC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de perplejidades:\n",
      "\n",
      "     Modelo  Perplejidad 20N  Perplejidad BAC\n",
      "0  Unigrama      1514.136822      1123.649051\n",
      "1   Bigrama      3119.263025      1451.294697\n",
      "2  Trigrama     18635.354236     21615.394482\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.DataFrame({\n",
    "    'Modelo': ['Unigrama', 'Bigrama', 'Trigrama'],\n",
    "    'Perplejidad 20N': [perplejidadUnigrama20N, perplejidadBigrama20N, perplejidadTrigrama20N],\n",
    "    'Perplejidad BAC': [perplejidadUnigramaBAC, perplejidadBigramaBAC, perplejidadTrigramaBAC]\n",
    "})\n",
    "\n",
    "print(\"Tabla de perplejidades:\\n\")\n",
    "print(resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El **modelo de unigramas** tiene la perplejidad más baja en ambos datasets, lo que indica que, desde una perspectiva de predicción, es el más efectivo según esta métrica\n",
    "- Los **modelos de bigramas y trigramas** presentan perplejidades más altas, posiblemente debido a la escasez de datos para ciertas combinaciones de palabras\n",
    "\n",
    "Sin embargo, es importante considerar que aunque el modelo de unigramas tiene la perplejidad más baja no captura las dependencias entre palabras, lo cual es esencial para generar oraciones coherentes!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de Oraciones Utilizando el Mejor Modelo (Modelo Unigrama)\n",
    "\n",
    "De acuerdo con los resultados obtenidos, el **modelo de unigramas** presenta la perplejidad más baja en ambos datasets, por lo que es considerado el mejor modelo según esta métrica.\n",
    "\n",
    "Aunque los modelos de unigramas no capturan las dependencias entre palabras, utilizaremos este modelo para generar oraciones porque lo dicen en elenunciado\n",
    "\n",
    "Definimos una función que, dado un modelo de unigramas y una palabra inicial, genera una oración de manera automática.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generarSentenciaUnigrama(modeloUnigrama, palabraInicial, tamanoVocabulario, maxLongitud=20):\n",
    "    \"\"\"\n",
    "    Genera una oración utilizando el modelo de unigramas, comenzando con una palabra dada\n",
    "    \n",
    "    Parámetros:\n",
    "    - modeloUnigrama (Counter): Modelo de unigramas\n",
    "    - palabraInicial (str): Palabra inicial de la oración\n",
    "    - tamanoVocabulario (int): Tamaño del vocabulario\n",
    "    - maxLongitud (int): Longitud máxima de la oración generad\n",
    "    \n",
    "    Retorna:\n",
    "    - str: Oración generada.\n",
    "    \"\"\"\n",
    "    oracion = [palabraInicial]\n",
    "    \n",
    "    totalFrecuencia = sum(modeloUnigrama.values()) + tamanoVocabulario\n",
    "    palabras = list(modeloUnigrama.keys())\n",
    "    frecuencias = [modeloUnigrama.get(palabra, 0) + 1 for palabra in palabras]  \n",
    "    \n",
    "    probabilidades = np.array(frecuencias) / totalFrecuencia\n",
    "    \n",
    "    for _ in range(maxLongitud - 1):\n",
    "        palabraSiguiente = np.random.choice(palabras, p=probabilidades)\n",
    "        oracion.append(palabraSiguiente)\n",
    "        \n",
    "        # Si la palabra es el token de fin de oración, detenemos la generación\n",
    "        if palabraSiguiente == '</s>':\n",
    "            break\n",
    "    \n",
    "    return ' '.join(oracion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de Generación de Oraciones y Análisis de Resultados\n",
    "\n",
    "Probamos la función de generación de oraciones con diferentes palabras iniciales para evaluar cómo el modelo de unigramas genera texto. Algunas de las palabras iniciales utilizadas son:\n",
    "\n",
    "- `<s>` (inicio de oración)\n",
    "- `the`\n",
    "- `NUM`\n",
    "- `this`\n",
    "- `it`\n",
    "- `i`\n",
    "- `he`\n",
    "- `she`\n",
    "- `they`\n",
    "- `we`\n",
    "\n",
    "Mostramos las oraciones generadas y analizamos su coherencia y características.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación de oraciones utilizando el modelo Unigrama:\n",
      "\n",
      "Palabra inicial: '<s>'\n",
      "Oración generada: <s> on require the an public on the can foil nose you corrections wouldn it you refugees discusses NUM i\n",
      "\n",
      "Palabra inicial: 'the'\n",
      "Oración generada: the be of me home were <UNK> point division faq oscillators performance could bursts NUM ziemans get NUM cases let\n",
      "\n",
      "Palabra inicial: 'NUM'\n",
      "Oración generada: NUM missions allegedly sale my kuwait priorities scott ax tj there access edu february the ___ silent before co of\n",
      "\n",
      "Palabra inicial: 'this'\n",
      "Oración generada: this you check america jews <s> have lives all intent acceptable kept past intents seat introduction mi0 date adobe matter\n",
      "\n",
      "Palabra inicial: 'it'\n",
      "Oración generada: it edu we car that fortune m immune constrains pacific NUM the the for very about in local <UNK> in\n",
      "\n",
      "Palabra inicial: 'i'\n",
      "Oración generada: i e i so way good is tongues for what a rodrigues disabled at citizen simple however soest r for\n",
      "\n",
      "Palabra inicial: 'he'\n",
      "Oración generada: he aug a short moslem mac j that respect 3dg university general the to pixel general NUM this jbf np\n",
      "\n",
      "Palabra inicial: 'she'\n",
      "Oración generada: she sell you d i NUM 0x37a disasterous ky3b rudy cars with a is we techreports system think cv043015 this\n",
      "\n",
      "Palabra inicial: 'they'\n",
      "Oración generada: they views the picks NUM NUM other not but empty but the istanbul and other very will anyone of god\n",
      "\n",
      "Palabra inicial: 'we'\n",
      "Oración generada: we s a you item gibson NUM up geocentrism regardless the is key if the frequency on like would are\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lista de palabras iniciales para probar\n",
    "palabrasIniciales = ['<s>', 'the', 'NUM', 'this', 'it', 'i', 'he', 'she', 'they', 'we']\n",
    "\n",
    "print(\"Generación de oraciones utilizando el modelo Unigrama:\\n\")\n",
    "\n",
    "for palabraInicial in palabrasIniciales:\n",
    "    if palabraInicial not in unigrama20N:\n",
    "        palabraInicial = '<UNK>'\n",
    "    \n",
    "    oracionGenerada = generarSentenciaUnigrama(unigrama20N, palabraInicial, tamanoVocabulario20N)\n",
    "    \n",
    "    print(f\"Palabra inicial: '{palabraInicial}'\")\n",
    "    print(f\"Oración generada: {oracionGenerada}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de las Oraciones Generadas\n",
    "\n",
    "Al revisar las oraciones generadas por el **modelo de unigramas**, observamos que:\n",
    "\n",
    "- Las palabras aparecen de manera independiente, sin considerar el contexto previo\n",
    "- Las oraciones suelen no tener de coherencia gramatical y semántica\n",
    "- Es común que las oraciones sean simplemente secuencias aleatorias de palabras del vocabulario, reflejando las frecuencias individuales de las palabras en el corpus.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de Oraciones Utilizando el Modelo Trigrama\n",
    "\n",
    "Con el objetivo de mejorar la coherencia y contexto de las oraciones generadas, implementamos una función para generar oraciones utilizando el **modelo de trigramas**. Al considerar dos palabras previas, el modelo trigrama puede capturar dependencias más largas.\n",
    "\n",
    "Realizamos pruebas similares a las anteriores y comparamos los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generarSentenciaTrigrama(modeloTrigrama, modeloBigrama, palabraInicial, tamanoVocabulario, maxLongitud=20):\n",
    "    \"\"\"\n",
    "    Genera una oración utilizando el modelo de trigramas, comenzando con una palabra dada\n",
    "\n",
    "    Parámetros:\n",
    "    - modeloTrigrama (defaultdict): Modelo de trigramqs\n",
    "    - modeloBigrama (defaultdict(Counter)): Modelo de bigramas\n",
    "    - palabraInicial (str): Palabra inicial de la oración\n",
    "    - tamanoVocabulario (int): Tamaño del vocabulario\n",
    "    - maxLongitud (int): Longitud máxima de la oración generad\n",
    "\n",
    "    Retorna:\n",
    "    - str: Oración generada.\n",
    "    \"\"\"\n",
    "    oracion = [palabraInicial]\n",
    "\n",
    "    posiblesSiguientes = modeloBigrama.get(palabraInicial, None)\n",
    "    if not posiblesSiguientes:\n",
    "        return ' '.join(oracion)\n",
    "\n",
    "    totalFrecuencia = sum(posiblesSiguientes.values()) + tamanoVocabulario\n",
    "    palabras = []\n",
    "    probabilidades = []\n",
    "\n",
    "    for palabra, frecuencia in posiblesSiguientes.items():\n",
    "        palabras.append(palabra)\n",
    "        probabilidad = (frecuencia + 1) / totalFrecuencia\n",
    "        probabilidades.append(probabilidad)\n",
    "\n",
    "    probabilidades = np.array(probabilidades)\n",
    "    probabilidades /= probabilidades.sum()\n",
    "\n",
    "    palabraSiguiente = np.random.choice(palabras, p=probabilidades)\n",
    "    oracion.append(palabraSiguiente)\n",
    "\n",
    "    for _ in range(maxLongitud - 2):\n",
    "        palabra1 = oracion[-2]\n",
    "        palabra2 = oracion[-1]\n",
    "        posiblesSiguientes = modeloTrigrama.get(palabra1, {}).get(palabra2, None)\n",
    "\n",
    "        if not posiblesSiguientes:\n",
    "            break\n",
    "\n",
    "        totalFrecuencia = sum(posiblesSiguientes.values()) + tamanoVocabulario\n",
    "        palabras = []\n",
    "        probabilidades = []\n",
    "\n",
    "        for palabra, frecuencia in posiblesSiguientes.items():\n",
    "            palabras.append(palabra)\n",
    "            probabilidad = (frecuencia + 1) / totalFrecuencia\n",
    "            probabilidades.append(probabilidad)\n",
    "\n",
    "        probabilidades = np.array(probabilidades)\n",
    "        probabilidades /= probabilidades.sum()\n",
    "\n",
    "        palabraSiguiente = np.random.choice(palabras, p=probabilidades)\n",
    "        oracion.append(palabraSiguiente)\n",
    "\n",
    "        # Si la palabra es el token de fin de oración, detenemos la generación\n",
    "        if palabraSiguiente == '</s>':\n",
    "            break\n",
    "\n",
    "    return ' '.join(oracion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generación de oraciones utilizando el modelo Trigrama:\n",
      "\n",
      "Palabra inicial: '<s>'\n",
      "Oración generada: <s> kime mongoose torolab ibm com ricardo rchland vnet ibm com internal mjp bwa kgn ibm com nareid helge helge\n",
      "\n",
      "Palabra inicial: 'the'\n",
      "Oración generada: the day following the end section x build xbegin NUM prog c x i am not sufficiently proved such borderline\n",
      "\n",
      "Palabra inicial: 'NUM'\n",
      "Oración generada: NUM NUM NUM minnesota vs vancouver saskatoon tue NUM apr NUM NUM z4jn wit NUM jesus himself be he should\n",
      "\n",
      "Palabra inicial: 'this'\n",
      "Oración generada: this utter nonsense if so will this kind of self defense purposes it s quiet on the same caliber with\n",
      "\n",
      "Palabra inicial: 'it'\n",
      "Oración generada: it is also the team <UNK> us r6 t4 mt44 y8 p 13s1 NUM qs tpi gg l NUM NUM\n",
      "\n",
      "Palabra inicial: 'i'\n",
      "Oración generada: i mistaken with this exact same phenomenon occurs with my lciii perhaps it is quite lightweight and easy configuration i\n",
      "\n",
      "Palabra inicial: 'he'\n",
      "Oración generada: he never reply again <UNK> are effectively cancelled these officials should spend NUM NUM 16mb ram pc week last august\n",
      "\n",
      "Palabra inicial: 'she'\n",
      "Oración generada: she saw an imaging tool that supports output and also those doing water lead analysis showed some guy came and\n",
      "\n",
      "Palabra inicial: 'they'\n",
      "Oración generada: they can hear it <UNK> size which the encrypted unit key u concatenated with the department of electrical engineering as\n",
      "\n",
      "Palabra inicial: 'we'\n",
      "Oración generada: we do this although as with their gods elohim to your zip code others charge monthly fees for access to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Generación de oraciones utilizando el modelo Trigrama:\\n\")\n",
    "\n",
    "for palabraInicial in palabrasIniciales:\n",
    "    if palabraInicial not in unigrama20N:\n",
    "        palabraInicial = '<UNK>'\n",
    "\n",
    "    oracionGenerada = generarSentenciaTrigrama(trigrama20N, bigrama20N, palabraInicial, tamanoVocabulario20N)\n",
    "\n",
    "    print(f\"Palabra inicial: '{palabraInicial}'\")\n",
    "    print(f\"Oración generada: {oracionGenerada}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de las Oraciones Generadas con el Modelo Trigrama\n",
    "\n",
    "Las oraciones generadas con el modelo trigrama muestran:\n",
    "\n",
    "- Una ligerq mejora en la coherencia, gracias a la consideración de un contexto más amplio\n",
    "- Persistencia de algunas limitaciones, como repeticiones y posibles incoherencias\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
