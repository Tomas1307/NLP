{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bac_files = 'data/BAC/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero debemos limpiar los datos que tienen entidades HTML esto lo vamos a manejar con bs4 que nos permite trabajar con este tipo de entidades sin eliminarlo manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_overwrite_xml(filepath):\n",
    "    # Intentar abrir el archivo con una codificación más flexible como 'latin-1'\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(filepath, 'r', encoding='latin-1') as file:\n",
    "            content = file.read()\n",
    "\n",
    "    # Usar BeautifulSoup para manejar entidades HTML dentro del XML\n",
    "    soup = BeautifulSoup(content, 'xml')\n",
    "\n",
    "    # Convertir el contenido limpio a una cadena de texto\n",
    "    cleaned_content = str(soup)\n",
    "\n",
    "    # Sobrescribir el archivo original con el contenido limpio\n",
    "    with open(filepath, 'w', encoding='utf-8') as file:\n",
    "        file.write(cleaned_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta a la carpeta donde están almacenados los archivos XML\n",
    "ruta_archivos = 'data/BAC/'\n",
    "\n",
    "# Procesar todos los archivos XML en la carpeta\n",
    "for archivo in os.listdir(ruta_archivos):\n",
    "    if archivo.endswith('.xml'):\n",
    "        archivo_completo = os.path.join(ruta_archivos, archivo)\n",
    "        clean_and_overwrite_xml(archivo_completo)\n",
    "        print(f\"Archivo procesado: {archivo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el procesamiento de los datos de BAC, donde tomamos las columnas como el nombre del archivo es decir, si el nombre es 4334776.male.24.Engineering.Aquarius, entonces las columnas son\n",
    "\n",
    "* id: 4334776\n",
    "* gender: male\n",
    "* age: 24\n",
    "* profession: Engineering\n",
    "* zodiac_sign: Aguarius\n",
    "\n",
    "Para manejar las entradas de los blogs decidimos agregar date, blog_content y number_of_posts. Esto se hizo para no perder informacion de las entradas realizadas por el usuario, de tal forma que, seria una fila en el dataframe por cada fecha que realizo una entrada el usuario. Si hay varias entradas por una fecha, se concatenan con un caracter definido por nosotros como ***POST** *  para identificar en donde empieza la siguiente entrada. Ademas, decidimos crear una funcion para convertir la fecha a formato que python identifique como YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to convert month names to numbers\n",
    "months = {\n",
    "    \"January\": \"01\", \"February\": \"02\", \"March\": \"03\", \"April\": \"04\", \n",
    "    \"May\": \"05\", \"June\": \"06\", \"July\": \"07\", \"August\": \"08\", \n",
    "    \"September\": \"09\", \"October\": \"10\", \"November\": \"11\", \"December\": \"12\"\n",
    "}\n",
    "\n",
    "# Function to convert date from format DD,Month,YYYY to YYYY-MM-DD\n",
    "def convert_date_to_yyyymmdd(date_str):\n",
    "    try:\n",
    "        # Separate the date into day, month, and year\n",
    "        day, month, year = date_str.split(',')\n",
    "\n",
    "        # Remove extra spaces and convert the month name to a number\n",
    "        day = day.strip().zfill(2)  # Ensure the day has two digits\n",
    "        month = months[month.strip()]\n",
    "        year = year.strip()\n",
    "\n",
    "        # Format the date as YYYY-MM-DD\n",
    "        formatted_date = f\"{year}-{month}-{day}\"\n",
    "        \n",
    "        return formatted_date\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting date {date_str}: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer el archivo XML, extraer las publicaciones agrupadas por fecha y devolver un DataFrame\n",
    "def bac_process(filepath):\n",
    "    try:\n",
    "        # Extraer atributos del nombre del archivo: id, gender, age, profession, zodiac_sign\n",
    "        filename = os.path.basename(filepath).replace('.xml', '')\n",
    "        columns = filename.split('.')\n",
    "\n",
    "        if len(columns) != 5:\n",
    "            raise ValueError(f\"El archivo {filename} no tiene el formato adecuado.\")\n",
    "\n",
    "        id_, gender, age, profession, zodiac_sign = columns\n",
    "\n",
    "        # Intentar abrir el archivo con una codificación más flexible como 'latin-1'\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            with open(filepath, 'r', encoding='latin-1') as file:\n",
    "                content = file.read()\n",
    "\n",
    "        # Usar BeautifulSoup para manejar el XML\n",
    "        soup = BeautifulSoup(content, 'xml')\n",
    "\n",
    "        # Extraer todas las dates y las publicaciones\n",
    "        dates = [date.text for date in soup.find_all('date')]\n",
    "        publicaciones = [post.text.strip() for post in soup.find_all('post')]\n",
    "\n",
    "        # Agrupar las publicaciones por su fecha\n",
    "        post_by_date = defaultdict(list)\n",
    "        for fecha, publicacion in zip(dates, publicaciones):\n",
    "            post_by_date[fecha].append(publicacion)\n",
    "\n",
    "        # Preparar los datos para el DataFrame\n",
    "        data = []\n",
    "        for fecha, posts in post_by_date.items():\n",
    "            # Concatenar las publicaciones con 'POST' y contar el número de publicaciones\n",
    "            blog_content = 'POST'.join(posts)\n",
    "            number_of_posts = len(posts)\n",
    "            \n",
    "            formatted_date = convert_date_to_yyyymmdd(fecha)\n",
    "\n",
    "            # Agregar una fila al conjunto de datos\n",
    "            data.append([id_, gender, age, profession, zodiac_sign, formatted_date, blog_content, number_of_posts])\n",
    "\n",
    "        # Crear un DataFrame para este archivo\n",
    "        df = pd.DataFrame(data, columns=['id', 'gender', 'age', 'profession', 'zodiac_sign', 'date', 'blog_content', 'number_of_posts'])\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar {filepath}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Ruta a la carpeta donde están almacenados los archivos XML\n",
    "ruta_archivos = 'data/BAC/'\n",
    "\n",
    "# Lista para almacenar los DataFrames de todos los archivos\n",
    "df_list = []\n",
    "\n",
    "# Procesar todos los archivos XML en la carpeta\n",
    "for archivo in os.listdir(ruta_archivos):\n",
    "    if archivo.endswith('.xml'):\n",
    "        archivo_completo = os.path.join(ruta_archivos, archivo)\n",
    "        df = bac_process(archivo_completo)\n",
    "        if not df.empty:\n",
    "            df_list.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_final = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Mostrar el DataFrame final\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('bac_unified.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bac_unified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
